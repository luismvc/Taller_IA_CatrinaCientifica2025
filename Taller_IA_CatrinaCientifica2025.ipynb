{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiwRunMC4Ent"
   },
   "source": [
    "# C√≥mo entrenar a tu robot: Un taller de introducci√≥n a la IA (Taller de procesamiento de im√°genes usando redes neuronales convolucionales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv-dlwb4oUHY"
   },
   "source": [
    "## 1. Introducci√≥n\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c8UjJ_Qd27X"
   },
   "source": [
    "<p align=\"justify\">El aprendizaje autom√°tico, tambi√©n conocido como <b>Machine Learning (ML)</b>, es el campo de estudio que se centra en <b>desarrollar algoritmos</b> y modelos capaces de <b>aprender y mejorar autom√°ticamente</b> a trav√©s de la experiencia y los <b>datos</b>. Con el avance de la tecnolog√≠a y la disponibilidad masiva de datos, el aprendizaje autom√°tico se ha convertido en una <b>herramienta</b> indispensable en una amplia gama de industrias y sectores, desde la <b>medicina y las finanzas hasta la tecnolog√≠a y el marketing</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lqTgQbNouRW"
   },
   "source": [
    "### ¬øQu√© diferencia hay entre inteligencia artificial, machine learning y Deep learning?\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1eAXxkRtyRvuyZq3KOPGPX00KIswfMvvf'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmLbmwu3qrHA"
   },
   "source": [
    "### Evoluci√≥n en el tiempo\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1ZzCX-pPvMHh1nvJ1Bw54BaPuAiwCWB1i'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG75agZkvfOo"
   },
   "source": [
    "### La era de la IA\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=11ZTDVigES5oGzGCEFfdYj-shRyQbzAI9'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQL3oIXHsi-u"
   },
   "source": [
    "### Neurona Biol√≥gica - La inspiraci√≥n del la IA\n",
    "\n",
    "<div>\n",
    "<img src='https://drive.google.com/uc?id=1XJewQqq_h2WS_DhB7vkru3kyNs0T5tWh' width=\"500\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkuHr_wBvQ-q"
   },
   "source": [
    "### Modelo de neurona: McCulloch-Pitts (1043)\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='https://drive.google.com/uc?id=1aunz3QWhWI6bvhxjPsqVHL1GrWOgBHNm' width=\"800\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIbRkdDi3qOU"
   },
   "source": [
    "### Perceptr√≥n\n",
    "\n",
    "<div>\n",
    "<img src='https://drive.google.com/uc?id=1R35hbuVzHyj6V5Xh566-dXoqJeBN78x8' width=\"600\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsE3vUstMw5c"
   },
   "source": [
    "### ¬øQu√© son las redes neuronals (Neuranal Netwoks)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcNT8CQp7ZB1"
   },
   "source": [
    " <p align=\"justify\">Una <b>Red Neuronal Artificial (NN)</b> es un conjunto de <b>nodos interconectados</b> de forma ordenada, distribuido <b>en capas</b>, a trav√©s del cual una <b>se√±al</b> de <b>entrada</b> se propaga para <b>producir</b> una <b>salida</b>. Se conocen as√≠ porque pretenden <b>emular de forma \"sencilla\"</b> el funcionamiento de las redes neuronales biol√≥gicas que se encuentran en el cerebro.\n",
    "\n",
    "La siguiente imagen muestra la estructura general de una NN.\n",
    "\n",
    "<div>\n",
    "<img src='https://drive.google.com/uc?id=1uXD6UVzjQbR0AJtOrX4xIU760cVYYdFD' width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "* imagen tomada de: https://www.pnas.org/doi/10.1073/pnas.1821594116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLONy4ZC4oVU"
   },
   "source": [
    "### ¬øPara qu√© son buenas las redes neuronales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiiuOyr_Z8A5"
   },
   "source": [
    "\n",
    "\n",
    "* Problemas con una larga lista de reglas.\n",
    "  * Cuando el enfoque tradicional falla, el aprendizaje autom√°tico (ML) o el aprendizaje profundo (DL) pueden ayudar.\n",
    "* Ambientes din√°micos.\n",
    "  * Cuando el ambiente es constantemente cambiente en el tiempo un efoque con base en DL puede adaptarse (aprender).\n",
    "* Descubrir informaci√≥n a partir de grandes cantidades de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqbwfOAx4zjq"
   },
   "source": [
    "### ¬øPara qu√© (t√≠picamente) no sirve el *Deep-Learning*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nALtRaA4to5"
   },
   "source": [
    "\n",
    "\n",
    "* Cuando se necesita explicabilidad.\n",
    "  * Los patrones aprendidos por un modelo de aprendizaje profundo\n",
    "normalmente son ininterpretables para un ser humano.\n",
    "* Cuando el enfoque tradicional es una mejor opci√≥n.\n",
    "  * Si se puede lograr lo que se necesita con un sistema simple basado en reglas.\n",
    "* Cuando los errores son inaceptables, ya que los resultados del modelo de aprendizaje profundo no siempre son predecibles.\n",
    "* Cuando **no** se tienen muchos datos*.\n",
    "  * Los modelos de aprendizaje profundo suelen requerir una cantidad \"bastante\" grande de datos para producir buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKuwprBKY0-g"
   },
   "source": [
    "### Regla 1 del ML Google's Handbook.\n",
    "\n",
    "\n",
    "\"*If you can build a **simple rule-based** system that doesn't require machine learning, do\n",
    "that.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkzBWHK4TfSx"
   },
   "source": [
    "### PyTorch vs TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMyLs5udS-7K"
   },
   "source": [
    "\n",
    "\n",
    "### ¬øQu√© son?\n",
    "\n",
    "**PyTorch** y **TensorFlow** son dos de las bibliotecas m√°s populares para el desarrollo de modelos de Machine Learning y Deep Learning.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Diferencias clave:\n",
    "\n",
    "| Caracter√≠stica         | PyTorch                           | TensorFlow                        |\n",
    "|------------------------|------------------------------------|------------------------------------|\n",
    "| Lanzamiento            | 2016 (Facebook)                   | 2015 (Google)                      |\n",
    "| Facilidad de uso       | M√°s f√°cil y \"pyth√≥nico\"           | M√°s robusto, pero algo m√°s complejo |\n",
    "| Comunidad              | Muy popular en investigaci√≥n       | Muy popular en producci√≥n          |\n",
    "| Soporte m√≥vil/embebido | Limitado, pero mejorando           | Mejor soporte (con TensorFlow Lite)|\n",
    "| Herramientas visuales  | Soporte b√°sico (`torch.utils.tensorboard`) | TensorBoard nativo                |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† ¬øCu√°l elegir?\n",
    "\n",
    "- **PyTorch**: Ideal para prototipado r√°pido e investigaci√≥n.\n",
    "- **TensorFlow**: Ideal para despliegue en producci√≥n y soluciones industriales.\n",
    "\n",
    "Ambos frameworks son muy potentes y est√°n en evoluci√≥n constante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t2yNjCqTVRp"
   },
   "source": [
    "## 2. Fundamentos de Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JsIKxcoRnap"
   },
   "source": [
    "### Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t5Z5Kylr_hN"
   },
   "source": [
    "#### ¬øQu√© son los tensores?\n",
    "\n",
    "En **PyTorch**, el objeto fundamental de trabajo es el **tensor**.  \n",
    "Un tensor es una estructura de datos muy similar a un arreglo (array) o matriz de **NumPy**,  \n",
    "pero con capacidades adicionales:\n",
    "\n",
    "- Puede trabajar en **CPU o GPU** (para acelerar c√°lculos).\n",
    "- Soporta **operaciones matem√°ticas eficientes** como producto punto, suma, transpuestas, etc.\n",
    "- Puede tener **cualquier n√∫mero de dimensiones**:\n",
    "  - Escalar ‚Üí  `5`\n",
    "  - Vector ‚Üí  `[1,2,3]`\n",
    "  - Matriz ‚Üí  `[[1,2],[3,4]]`\n",
    "  - Tensores de mayor orden ‚Üí dimensi√≥n mayor o igual a tres son √∫tiles en im√°genes, audio, video, etc.\n",
    "\n",
    "En resumen: un tensor es la **unidad b√°sica de datos en PyTorch**, como lo son los arrays en **NumPy**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LTEHh_mXRhhf",
    "outputId": "a091ff10-1cf5-461d-a465-690eb2887e14"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0crts8bRxQE",
    "outputId": "26cce9e8-92bf-4f16-9867-ba474c3bf8f3"
   },
   "outputs": [],
   "source": [
    "# Escalar (0D)\n",
    "escalar = torch.tensor(7)\n",
    "print(\"Escalar:\", escalar)\n",
    "print(\"Dimensiones:\", escalar.ndim)\n",
    "\n",
    "# Vector (1D)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "print(\"\\nVector:\", vector)\n",
    "print(\"Dimensiones:\", vector.ndim)\n",
    "\n",
    "# Matriz (2D)\n",
    "matriz = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"\\nMatriz:\\n\", matriz)\n",
    "print(\"Dimensiones:\", matriz.ndim)\n",
    "\n",
    "# Tensor 3D (ejemplo: 2 matrices de 2x2)\n",
    "tensor_3d = torch.tensor([[[1,2],[3,4]], [[5,6],[7,8]]])\n",
    "print(\"\\nTensor 3D:\\n\", tensor_3d)\n",
    "print(\"Dimensiones:\", tensor_3d.ndim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMSJ5zhGtlRf"
   },
   "source": [
    "Tensores en el GPU (si est√° disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTp0EJnYtKv7",
    "outputId": "1b6ed23d-20a9-44f1-b316-e3ab7732312c"
   },
   "outputs": [],
   "source": [
    "# Verificar si hay GPU disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Usando dispositivo:\", device)\n",
    "\n",
    "# Crear tensor directamente en GPU\n",
    "x_gpu = torch.ones((3,3), device=device)\n",
    "print(\"\\nTensor en GPU:\\n\", x_gpu)\n",
    "\n",
    "# Mover un tensor de CPU a GPU\n",
    "x_cpu = torch.ones((3,3))\n",
    "x_cpu_to_gpu = x_cpu.to(device)\n",
    "print(\"\\nTensor movido de CPU a GPU:\\n\", x_cpu_to_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJMMi69b2ixC"
   },
   "source": [
    "### Flujo de trabajo (*Workflow*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHDMXYLW5mQL"
   },
   "source": [
    "<p align=\"justify\">La <b>esencia del aprendizaje autom√°tico</b> (<em>ML</em>, por sus siglas en ingl√©s) y el aprendizaje profundo (<em>DL</em>) consiste en que a partir de la adquisici√≥n de datos, se construye un modelo (como una red neuronal) para <b>descubrir patrones</b> en ellos y usar esos patrones para \"predecir el futuro\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xS8i2qOa5qTy"
   },
   "source": [
    "El \"esquema\" o flujo de trabajo que se sigue para la implementaci√≥n de modelos de aprendizaje autom√°tico particularmetne en PyTorch es:\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1W1vuZFx0nYRbvqVdnHnOhfB-N6REpJgy'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LF5L_GI6u6T"
   },
   "source": [
    "En resumen, el aprendizaje autom√°tico es un juego de dos partes:  \n",
    "1. Convertir tus datos, sean los que sean, en n√∫meros (una representaci√≥n).  \n",
    "2. Elegir o construir un modelo que aprenda esa representaci√≥n de la mejor manera posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hptTfnnCBg8Y"
   },
   "source": [
    "## 3. Preparando los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Nf5cr8a6NAo"
   },
   "source": [
    "\n",
    "\n",
    "Los \"datos\" en el aprendizaje autom√°tico pueden ser casi cualquier cosa que puedas imaginar.\n",
    "- Una tabla de n√∫meros (como una hoja de c√°lculo en Excel),\n",
    "- im√°genes de cualquier tipo,\n",
    "- videos (¬°YouTube tiene muchos datos!),\n",
    "- archivos de audio como canciones o podcasts,\n",
    "- estructuras de prote√≠nas,\n",
    "- texto,\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qAm1MvW7BsK"
   },
   "source": [
    "#### Ejemplo - Creando algunos datos.\n",
    "\n",
    "Usaremos regresi√≥n lineal para crear los datos con par√°metros conocidos (cosas que un modelo puede aprender) y luego utilizaremos PyTorch para ver si podemos construir un modelo que estime estos par√°metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVusJPrd7KJ5"
   },
   "source": [
    "Regresi√≥n Lineal:\n",
    "\n",
    "$y=wX+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DetBZHHtp2H"
   },
   "outputs": [],
   "source": [
    "# Importando las bibliotecas de funciones\n",
    "import torch\n",
    "\n",
    "#   Bloque para la implementaci√≥n de redes neuronaels\n",
    "from torch import nn\n",
    "\n",
    "#   Biblioteca para graficar\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS7O5551v97H"
   },
   "source": [
    "* Crear un conjunto de datos en forma de l√≠nea recta utilizando la f√≥rmula de regresi√≥n lineal ($y=wX+b$).\n",
    "  * Establecer `w=0.7` y `b=0.3`, y debe haber al menos `100` puntos de datos en total.\n",
    "  * Los valores de `X` deben estar entre `0` y `1`.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvFaxWTJ8XTl",
    "outputId": "b6f889fd-9bcf-4c7e-cfb3-f37fc6a43c87"
   },
   "outputs": [],
   "source": [
    "# Creadon par√°metro \"conocidos\"\n",
    "\n",
    "# ---\n",
    "# Agregue sus valores aqu√≠\n",
    "w =\n",
    "b =\n",
    "\n",
    "start =\n",
    "end =\n",
    "step =\n",
    "#-----\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = w * X + b\n",
    "\n",
    "# Mostradon los primeros 10 datos (X,y)\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVVjHXJZ8sbY"
   },
   "source": [
    "Ahora avanzaremos hacia la construcci√≥n de un *modelo* que pueda aprender la relaci√≥n entre `X` (**caracter√≠sticas**) y `y` (**etiquetas**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrBPRchs8_UA"
   },
   "source": [
    "### Divisi√≥n de los datos en conjuntos de **entrenamiento**/**validaci√≥n** y **prueba**\n",
    "\n",
    "Antes de construir un modelo, necesitamos dividir los datos.\n",
    "\n",
    "Uno de los pasos m√°s importantes en un proyecto de aprendizaje autom√°tico es crear un conjunto de entrenamiento y un conjunto de prueba (y, cuando sea necesario, un conjunto de validaci√≥n).\n",
    "\n",
    "Cada divisi√≥n del conjunto de datos cumple una funci√≥n espec√≠fica:\n",
    "\n",
    "| Divisi√≥n | Prop√≥sito | Cantidad del total de datos | ¬øCon qu√© frecuencia se usa? |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **Conjunto de entrenamiento** | El modelo aprende de estos datos (como los materiales de estudio que revisas durante el semestre). | ~60-80% | Siempre |\n",
    "| **Conjunto de validaci√≥n** | El modelo se ajusta con estos datos (como el examen de pr√°ctica que tomas antes del examen final). | ~10-20% | Frecuentemente, pero no siempre |\n",
    "| **Conjunto de prueba** | El modelo se eval√∫a con estos datos para probar lo que ha aprendido (como el examen final que tomas al final del semestre). | ~10-20% | Siempre |\n",
    "\n",
    "Por ahora, solo usaremos un conjunto de entrenamiento y un conjunto de prueba, lo que significa que tendremos un conjunto de datos para que nuestro modelo aprenda y otro para evaluarlo.\n",
    "\n",
    "Podemos crearlos dividiendo nuestros tensores `X` y `y`.\n",
    "\n",
    "> <p align=\"justify\"><b>Nota:</b> Al trabajar con datos del mundo real, este paso generalmente se realiza al inicio de un proyecto. Es importante resaltar que <b>el conjunto de prueba siempre debe mantenerse separado de todos los dem√°s datos</b>. Queremos que nuestro modelo aprenda de los datos de entrenamiento y luego evaluarlo con los datos de prueba para obtener una indicaci√≥n de qu√© tan bien se <em>generaliza</em> a ejemplos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hobxwt3F_iFv"
   },
   "source": [
    "#### Ejemplo - Dividiendo los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWl_6lKex0wt"
   },
   "source": [
    "* Dividir los datos en 80% para entrenamiento y 20% para pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4DUo_CL8X8w",
    "outputId": "2e82a462-0c54-43d1-d941-2501be29bca4"
   },
   "outputs": [],
   "source": [
    "# Creando el conjunto de entrenamiento y prube\n",
    "\n",
    "# ---\n",
    "# Agregue sus valores aqu√≠\n",
    "#   Porcesntaje de entramiento\n",
    "entrenamiento =\n",
    "# ---\n",
    "\n",
    "train_split = int(entrenamiento* len(X)) # 80% of data used for training set, 20% for testing\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMuh2-GL_9cH"
   },
   "source": [
    "Tenemos 80 muestras para entrenamiento (`X_train` y `y_train`) y 20 muestras para prueba (`X_test` y `y_test`).\n",
    "\n",
    "El modelo que implementemos intentar√° aprender la relaci√≥n entre `X_train` y `y_train`, y luego evaluaremos lo que ha aprendido en `X_test` y `y_test`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfjKenpNARuT"
   },
   "source": [
    "#### Ejemplo - Funci√≥n para visualizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cI2q7eRN_tQL"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(train_data   = X_train,\n",
    "                     train_labels = y_train,\n",
    "                     test_data    = X_test,\n",
    "                     test_labels  = y_test,\n",
    "                     predictions  = None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Entrenamiento\")\n",
    "\n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Prueba\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predicciones\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "A93b0V4IAZ9z",
    "outputId": "fed376bd-99fa-4336-b25f-2d0354d86cca"
   },
   "outputs": [],
   "source": [
    "plot_predictions( X_train, y_train, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pf1th2TKlO_"
   },
   "source": [
    "## 4. Red Neuronal B√°sica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJrvoKK1Aq_c"
   },
   "source": [
    "\n",
    "\n",
    "PyTorch cuenta con cuatro (m√°s o menos) m√≥dulos esenciales que puedes usar para crear casi cualquier tipo de red neuronal que imagines.\n",
    "\n",
    "- M√≥dulos escenciales\n",
    "\n",
    "  - [`torch.nn`](https://pytorch.org/docs/stable/nn.html),\n",
    "    -  [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter)\n",
    "    - [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)\n",
    "  - [`torch.optim`](https://pytorch.org/docs/stable/optim.html),\n",
    "  - [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) y\n",
    "  - [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html).\n",
    "\n",
    "Por ahora, nos enfocaremos en los primeros dos (`torch.nn`, `torch.optim`) y abordaremos los otros dos m√°s adelante (aunque podr√≠as intuir para qu√© sirven).\n",
    "\n",
    "| M√≥dulo de PyTorch | ¬øQu√© hace? |\n",
    "| ----- | ----- |\n",
    "| [`torch.nn`](https://pytorch.org/docs/stable/nn.html) | Contiene todos los bloques b√°sicos para los gr√°ficos computacionales (esencialmente una serie de c√°lculos ejecutados de una manera particular). |\n",
    "| [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter) | Almacena tensores que pueden usarse con `nn.Module`. Si `requires_grad=True`, se calculan autom√°ticamente los gradientes (utilizados para actualizar los par√°metros del modelo mediante [**descenso de gradiente**](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html)), lo cual se conoce como \"autograd\".  |\n",
    "| [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) | La clase base para todos los m√≥dulos de redes neuronales; todos los bloques b√°sicos de redes neuronales son subclases de esta. Si est√°s construyendo una red neuronal en PyTorch, tus modelos deben ser subclases de `nn.Module`. Requiere implementar un m√©todo `forward()`. |\n",
    "| [`torch.optim`](https://pytorch.org/docs/stable/optim.html) | Contiene varios algoritmos de optimizaci√≥n (estos indican a los par√°metros del modelo almacenados en `nn.Parameter` c√≥mo deben cambiar para mejorar el descenso de gradiente y reducir la p√©rdida). |\n",
    "| `def forward()` | Todas las subclases de `nn.Module` requieren un m√©todo `forward()`, que define los c√°lculos que se realizar√°n en los datos pasados al `nn.Module` en particular (por ejemplo, la f√≥rmula de la regresi√≥n lineal mencionada anteriormente). |\n",
    "\n",
    "\n",
    "En resumen,\n",
    "\n",
    "* `nn.Module` contiene los bloques grandes (capas)\n",
    "* `nn.Parameter` contiene los par√°metros m√°s peque√±os, como pesos y sesgos (al combinarlos, forman `nn.Module`(s))\n",
    "* `forward()` indica a los bloques grandes c√≥mo realizar los c√°lculos en las entradas (tensores llenos de datos) dentro de `nn.Module`(s)\n",
    "* `torch.optim` contiene m√©todos de optimizaci√≥n para mejorar los par√°metros dentro de `nn.Parameter` y representar mejor los datos de entrada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E68G_xm-KWJN"
   },
   "source": [
    "### Bloque b√°sico para crear un modelo (Red Neuronal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GxiDZAPK9fJ"
   },
   "source": [
    "\n",
    "<img src='https://drive.google.com/uc?id=1ulrbp-KacueQ8S2QCDfwzf4wc-XDG3cQ'>\n",
    "\n",
    "Bloques b√°sicos para crear un modelo en PyTorch mediante la clase `nn.Module`.\n",
    "  * Para los objetos que son clases de `nn.Module`, se debe definir el m√©todo `forward()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GTgpRLmLKs4"
   },
   "source": [
    "A partir de la estructura general de un modelo en PyTorch y, con los datos que hemos creado antes, vamos a **construir un modelo** para usar los puntos azules y predecir los puntos verdes.\n",
    "\n",
    "Nota. Para este ejercicios, vamos a replicar un modelo de regresi√≥n lineal est√°ndar usando PyTorch puro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCkIH4iDs2wg"
   },
   "source": [
    "#### Ejemplo - Implementando un modelo b√°sico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AS8IsSruAfpr"
   },
   "outputs": [],
   "source": [
    "# Creando una clase para un modelo de regresi√≥n Lineal\n",
    "class LinearRegressionModel(nn.Module): # <- pr√°ticamente todo en PyTorch es un nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, # <- Iniciar con pesos aleatorios (estos se ajustan conforme el modelo aprende)\n",
    "                                                dtype=torch.float), # <- usar tipos de dato float32\n",
    "                                   requires_grad=True)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(1, # <- Iniciar con un sesgo aleatorio (este se ajusta conforme el modelo aprende)\n",
    "                                            dtype=torch.float), # <- usar tipos de dato float32\n",
    "                                requires_grad=True)\n",
    "\n",
    "    # Forward describe qu√© hace tu red con los datos cuando los recibe\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" datos de entrada\n",
    "        return self.weights * x + self.bias # <- expresi√≥n para la regresi√≥n lineal (y = m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mg6NvDYteyU"
   },
   "source": [
    "\n",
    "Ahora que hemos visto estos conceptos, vamos a crear una instancia del modelo con la clase que hemos creado y revisar sus par√°metros usando [`.parameters()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qHkcWm_tXTx",
    "outputId": "555c3a95-c490-4bed-a0dc-6690d0c3ef4d"
   },
   "outputs": [],
   "source": [
    "# Inicializamos una \"semilla\" aleatoria ya que nn.Parameter se inicializa aleatoriamente\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Creamos una instancia del modelo\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Revisamos los par√°metros de la instancia creada\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNTBF-0pt3Yz"
   },
   "source": [
    "Tambi√©n podemos obtener el estado (lo que contiene el modelo) usando [`.state_dict()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vS7VNhHXtx8M",
    "outputId": "c2e56e83-284b-4bb1-99bd-5b9f4d1c1ed2"
   },
   "outputs": [],
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4OjnmZCuEp5"
   },
   "source": [
    "- Los valores de `weights` y `bias` en `model_0.state_dict()` aparecen como tensores de punto flotante aleatorios. Esto se debe a que los inicializamos anteriormente usando `torch.randn()`.\n",
    "\n",
    "- Esencialmente, queremos comenzar con par√°metros aleatorios y lograr que el modelo los actualice hacia los par√°metros que mejor se ajusten a nuestros datos (los valores fijos de `weight` y `bias` que establecimos al crear nuestros datos de l√≠nea recta).\n",
    "\n",
    "- Dado que nuestro modelo comienza con valores aleatorios, en este momento tendr√° un bajo poder predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Mo8mBBuVsl"
   },
   "source": [
    "##### Haciendo predicciones usando `torch.inference_mode()`\n",
    "\n",
    "Para comprobar esto, podemos pasarle los datos de prueba `X_test` y ver qu√© tan cerca predice `y_test`.\n",
    "\n",
    "Cuando pasamos datos a nuestro modelo, estos pasar√°n por el m√©todo `forward()` del modelo y producir√°n un resultado usando el c√°lculo que hemos definido.\n",
    "\n",
    "Hagamos algunas predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHrIXDsot67v"
   },
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C619BgEsuyv0"
   },
   "source": [
    "Probablemente notaste que usamos [`torch.inference_mode()`](https://pytorch.org/docs/stable/generated/torch.inference_mode.html) como un [administrador de contexto](https://realpython.com/python-with-statement/) (eso es lo que indica `with torch.inference_mode():`) para hacer las predicciones.\n",
    "\n",
    "Como sugiere el nombre, `torch.inference_mode()` se usa cuando un modelo se emplea para inferencia (realizar predicciones).\n",
    "\n",
    "`torch.inference_mode()` desactiva varias funciones (como el seguimiento de gradientes, que es necesario para el entrenamiento pero no para la inferencia) para hacer que los **forward-passes** (datos que pasan por el m√©todo `forward()`) sean m√°s r√°pidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MONADip1Wnv"
   },
   "source": [
    "Hemos hecho algunas predicciones, veamos c√≥mo se ven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7e0PMCBunFm",
    "outputId": "136bfafe-f6c0-46a7-f0fc-0a3e533fe1f8"
   },
   "outputs": [],
   "source": [
    "# Veamos las predicciones\n",
    "print(f\"Number of testing samples: {len(X_test)}\")\n",
    "print(f\"Number of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted values:\\n{y_preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxMaC46bvO9Z"
   },
   "source": [
    "Observa c√≥mo hay un valor de predicci√≥n por cada muestra de prueba.\n",
    "\n",
    "Esto se debe al tipo de datos que estamos utilizando. En nuestra l√≠nea recta, un valor de `X` se asocia a un valor de `y`.\n",
    "\n",
    "Sin embargo, los modelos de aprendizaje autom√°tico son muy flexibles. Podr√≠as tener 100 valores de `X` asociados a uno, dos, tres o 10 valores de `y`, dependiendo del proyecto en el que est√©s trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD6N-pHs1uHa"
   },
   "source": [
    "Vamos a visualizarlas con nuestra funci√≥n `plot_predictions()` que creamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "K8dZrHUMvL6f",
    "outputId": "478e2515-13aa-46ec-8a7e-fad0d5fbf2b7"
   },
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FXakE3gvvPS"
   },
   "source": [
    "**Esas predicciones se ven bastante mal!!!**\n",
    "\n",
    "Aunque tiene sentido, si recordamos que nuestro modelo solo est√° usando valores de par√°metros aleatorios para hacer las predicciones.\n",
    "\n",
    "Ni siquiera ha analizado los puntos azules para intentar predecir los puntos verdes.\n",
    "\n",
    "Es hora de cambiar eso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PibbqwUlv527"
   },
   "source": [
    "### Entrenando el modelo\n",
    "\n",
    "Ahora mismo, nuestro modelo est√° haciendo predicciones utilizando par√°metros aleatorios para realizar los c√°lculos, b√°sicamente est√° adivinando (de manera aleatoria).\n",
    "\n",
    "Para solucionar esto, podemos actualizar sus par√°metros internos (tambi√©n me refiero a *par√°metros* como patrones), los valores de `weights` y `bias` que configuramos aleatoriamente usando `nn.Parameter()` y `torch.randn()`, para que representen mejor los datos.\n",
    "\n",
    "Podr√≠amos codificar esto manualmente, pero ¬øentonces de que sirve el modelo?\n",
    "\n",
    "- La mayor√≠a de las veces, no sabr√°s cu√°les son los par√°metros ideales para un modelo.\n",
    "\n",
    "- En su lugar, es mucho m√°s adecuado escribir c√≥digo para ver si el modelo puede intentar descubrir los par√°metros/patrones por s√≠ mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iQT59dUxGJz"
   },
   "source": [
    "#### Creando una funci√≥n de p√©rdida (**loss function**) y un optimizador (**optimizer**) en PyTorch\n",
    "\n",
    "Para que nuestro modelo actualice sus par√°metros por s√≠ mismo, necesitaremos agregar algunas cosas m√°s a nuestra receta. Esas \"cosas\" son una **funci√≥n de p√©rdida** y un **optimizador**:\n",
    "\n",
    "| Funci√≥n | ¬øQu√© hace? | ¬øD√≥nde se encuentra en PyTorch? | Valores comunes |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **Funci√≥n de p√©rdida** | Mide cu√°n equivocadas est√°n las predicciones de tu modelo<br>(por ejemplo, `y_preds`) en comparaci√≥n con las etiquetas<br> verdaderas (por ejemplo, `y_test`). Mientras m√°s bajo, mejor. | PyTorch tiene muchas funciones de p√©rdida predefinidas en [`torch.nn`](https://pytorch.org/docs/stable/nn.html#loss-functions). | Error absoluto medio (MAE) para problemas de regresi√≥n ([`torch.nn.L1Loss()`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)).<br> Entrop√≠a cruzada binaria para problemas de clasificaci√≥n binaria ([`torch.nn.BCELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)). |\n",
    "| **Optimizador** | Indica a tu modelo c√≥mo actualizar sus par√°metros internos<br> para reducir al m√°ximo la p√©rdida. | Puedes encontrar varias implementaciones de funciones de optimizaci√≥n<br> en [`torch.optim`](https://pytorch.org/docs/stable/optim.html). | Descenso de gradiente estoc√°stico ([`torch.optim.SGD()`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)).<br> Optimizador Adam ([`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)). |\n",
    "\n",
    "- Dependiendo del tipo de problema en el que est√©s trabajando, se elegir√° la funci√≥n de p√©rdida y el optimizador a utilizar.\n",
    "\n",
    "Existen algunos valores comunes que se sabe que funcionan bien, como\n",
    "- el optimizador SGD (descenso de gradiente estoc√°stico) o Adam.\n",
    "- Y la funci√≥n de p√©rdida MAE (error absoluto medio) para problemas de regresi√≥n (predecir un n√∫mero) o\n",
    "- la funci√≥n de p√©rdida de entrop√≠a cruzada binaria para problemas de clasificaci√≥n (predecir una cosa u otra).\n",
    "\n",
    "Para nuestro problema, como estamos prediciendo un n√∫mero, usaremos MAE (que est√° bajo `torch.nn.L1Loss()`) en PyTorch como nuestra funci√≥n de p√©rdida.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1g3T2pespFLRjoYrPlgcjPp2pAzG0MSQR'>\n",
    "\n",
    "*El error absoluto medio (MAE, en PyTorch: `torch.nn.L1Loss`) mide la diferencia absoluta entre dos puntos (predicciones y etiquetas) y luego toma la media de todos los ejemplos.*\n",
    "\n",
    "Y utilizaremos SGD, `torch.optim.SGD(params, lr)`, donde:\n",
    "\n",
    "* `params` son los par√°metros del modelo objetivo que te gustar√≠a optimizar (por ejemplo, los valores de `weights` y `bias` que configuramos aleatoriamente antes).\n",
    "* `lr` es la tasa de aprendizaje (**learning rate**) a la que te gustar√≠a que el optimizador actualice los par√°metros.\n",
    "  - Un valor m√°s alto significa que el optimizador intentar√° actualizaciones m√°s grandes (estas pueden ser a veces demasiado grandes y el optimizador no funcionar√°),\n",
    "  - un valor m√°s bajo significa que el optimizador intentar√° actualizaciones m√°s peque√±as (estas pueden ser demasiado peque√±as y el optimizador tardar√° mucho en encontrar los valores ideales).\n",
    "  \n",
    "La **tasa de aprendizaje** se considera un **hiperpar√°metro** (que es configurado por el desarrollador). Los valores comunes para la tasa de aprendizaje son `0.01`, `0.001`, `0.0001`. Sin embargo, estos tambi√©n pueden ajustarse con el tiempo (esto se llama [programaci√≥n de tasa de aprendizaje](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Tx4AZw8voe6"
   },
   "outputs": [],
   "source": [
    "# Create the loss function\n",
    "loss_fn = nn.L1Loss() # MAE loss est√° implementada como L1Loss\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # par√°metros del modelo\n",
    "                            lr=0.01) # lr:learning rate (cu√°nto debe cambiar el optimizador los par√°metros en cada paso, mayor->menos estable, menor->podr√≠a tomar mucho tiempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxKUpupEy9oz"
   },
   "source": [
    "#### Ciclo de optimizaci√≥n en PyTorch\n",
    "\n",
    "Ahora que tenemos una funci√≥n de p√©rdida y un optimizador, es momento de crear un **ciclo de entrenamiento** (y un **ciclo de prueba**).\n",
    "\n",
    "- El ciclo de entrenamiento consiste en que el modelo pase por los datos de entrenamiento y aprenda las relaciones entre las `features` y las `labels`.\n",
    "\n",
    "- El ciclo de prueba implica pasar por los datos de prueba y evaluar qu√© tan buenos son los patrones que el modelo aprendi√≥ en los datos de entrenamiento (el modelo nunca ve los datos de prueba durante el entrenamiento).\n",
    "\n",
    "Cada uno de estos se llama \"ciclo\" porque queremos que nuestro modelo vea (recorra) cada muestra en cada conjunto de datos.\n",
    "\n",
    "Para crear estos ciclos, vamos a escribir un _for_-_loop_ (`for`) en Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl2nuTmdzmzt"
   },
   "source": [
    "#### Etapa (ciclo) de entrenamiento en PyTorch\n",
    "\n",
    "Para el ciclo de entrenamiento, construiremos los siguientes pasos:\n",
    "\n",
    "\n",
    "| N√∫mero | Nombre del paso | ¬øQu√© hace? | Ejemplo de c√≥digo |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | *Forward pass* | El modelo pasa por todos los datos de entrenamiento una vez,<br> realizando los c√°lculos de su funci√≥n `forward()`. | `model(x_train)` |\n",
    "| 2 | Calcular la p√©rdida | Las salidas del modelo (predicciones) se comparan con la verdad<br> fundamental y se eval√∫a cu√°n incorrectas son. | `loss = loss_fn(y_pred, y_train)` |\n",
    "| 3 | Poner los gradientes a cero | Los gradientes del optimizador se ponen a cero (por defecto se acumulan)<br> para que puedan ser recalculados para el paso de entrenamiento espec√≠fico. | `optimizer.zero_grad()` |\n",
    "| 4 | Retropropagaci√≥n sobre la p√©rdida | Calcula el gradiente de la p√©rdida con respecto a cada par√°metro del modelo<br> que se debe actualizar (cada par√°metro con `requires_grad=True`). | `loss.backward()` |\n",
    "| 5 | Actualizar el optimizador (**descenso de gradiente**) | Actualiza los par√°metros con `requires_grad=True` con respecto a<br> los gradientes de la p√©rdida para mejorarlos. | `optimizer.step()` |\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1yJgiEGC6oWn0ztagqLz_G6g2evlGwCR0'>\n",
    "\n",
    "\n",
    "> **Nota:** Lo anterior es solo un ejemplo de c√≥mo podr√≠an ordenarse o describirse los pasos. Con experiencia, descubrir√°s que los ciclos de entrenamiento en PyTorch pueden ser bastante flexibles.\n",
    ">\n",
    "> En cuanto al orden de los pasos, el orden anterior es un buen orden por defecto, pero es posible que veas √≥rdenes ligeramente diferentes. Algunas reglas generales:\n",
    "> * Calcula la p√©rdida (`loss = ...`) *antes* de realizar la retropropagaci√≥n sobre ella (`loss.backward()`).\n",
    "> * Pon los gradientes a cero (`optimizer.zero_grad()`) *antes* de calcular los gradientes de la p√©rdida con respecto a cada par√°metro del modelo (`loss.backward()`).\n",
    "> * Actualiza el optimizador (`optimizer.step()`) *despu√©s* de realizar la retropropagaci√≥n sobre la p√©rdida (`loss.backward()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUJDS3ah5QRo"
   },
   "source": [
    "#### Etapa (ciclo) de prueba en PyTorch\n",
    "\n",
    "\n",
    "En cuanto al ciclo de prueba (evaluaci√≥n de nuestro modelo), los pasos t√≠picos incluyen:\n",
    "\n",
    "| N√∫mero | Nombre del paso | ¬øQu√© hace? | Ejemplo de c√≥digo |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | *Forward pass* | El modelo pasa por todos los datos de prueba una vez, realizando los c√°lculos de su funci√≥n `forward()`. | `model(x_test)` |\n",
    "| 2 | Calcular la p√©rdida | Las salidas del modelo (predicciones) se comparan con la verdad fundamental y se eval√∫a cu√°n incorrectas son. | `loss = loss_fn(y_pred, y_test)` |\n",
    "| 3 | Calcular m√©tricas de evaluaci√≥n (opcional) | Junto con el valor de la p√©rdida, puede que desees calcular otras m√©tricas de evaluaci√≥n, como la precisi√≥n en el conjunto de prueba. | Funciones personalizadas |\n",
    "\n",
    "Observa que el ciclo de prueba no incluye realizar la retropropagaci√≥n (`loss.backward()`) ni actualizar el optimizador (`optimizer.step()`), esto es porque no se cambian par√°metros en el modelo durante las pruebas, ya se han calculado. Para las pruebas, solo nos interesa la salida del pase hacia adelante a trav√©s del modelo.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1fePzzXh4FK0l_NAC9R9Dv60A0qaabGPL'>\n",
    "\n",
    "\n",
    "\n",
    "Vamos a juntar todo lo anterior y entrenar nuestro modelo durante 100 **√©pocas** y lo evaluaremos cada 10 √©pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOe2JYpBy3_s",
    "outputId": "be30b65c-23e8-4a47-837d-bfe8bf7f3f24"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Estableciendo el n√∫mero de √©pocas (cu√°ntas veces el modelo pasar√° sobre los datos de entrenamiento)\n",
    "epochs = 100\n",
    "\n",
    "# Crear listas de p√©rdidas vac√≠as para realizar un seguimiento de los valores\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #----------------------\n",
    "    ### Entrenamiento\n",
    "\n",
    "    # Poner el modelo en modo de entrenamiento (este es el estado predeterminado de un modelo)\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Calculando la predicci√≥n por medio de la funci√≥n Forward y los datos de entrenamiento\n",
    "    y_pred = model_0(X_train)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # 2. Calcular la p√©rdida (¬øcu√°n diferentes son las predicciones de nuestros modelos con respecto a la referencia?)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. poner en cero todos los gradientes acumulados del optimizador\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. calculando los gradientes de la p√©rdida (loss) con respecto a todos los par√°metros del modelo\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Actualizando los valores de los par√°metros (los pesos del modelo).\n",
    "    optimizer.step()\n",
    "    #----------------------\n",
    "\n",
    "    #----------------------\n",
    "    ### Testing\n",
    "\n",
    "    # Colocando el modelo en modo de evaluaci√≥n\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      # 1. Haciendo la predicci√≥n\n",
    "      test_pred = model_0(X_test)\n",
    "\n",
    "      # 2. Caculando la p√©rdidad sobre los datos de prueba\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Mostrando los resultados pariciales\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n",
    "\n",
    "    #----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASQZXh0-5tGL"
   },
   "source": [
    "Observa como la p√©rdida est√° disminuyendo con cada √©poca, vamos a graficarlo para verlo mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "qchMiVp15pLY",
    "outputId": "a540d393-4ef2-410b-9a98-301ec4ec78be"
   },
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Loss (Entrenamiento)\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Loss (Prueba)\")\n",
    "plt.title(\"Curvas de p√©rdida\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epocas\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wmFXNY057d3"
   },
   "source": [
    "- Las **curvas de p√©rdida (_loss_)** muestran c√≥mo la p√©rdida disminuye con el tiempo. Recuerda, la p√©rdida es la medida de cu√°n *incorrecto* est√° tu modelo, por lo que mientras m√°s baja, mejor.\n",
    "\n",
    "Pero, ¬øpor qu√© disminuy√≥ la p√©rdida?\n",
    "\n",
    "Bueno, gracias a la funci√≥n de p√©rdida y al optimizador, los par√°metros internos del modelo (`weights` y `bias`) fueron actualizados para reflejar mejor los patrones subyacentes en los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qUPlzZm6JLQ"
   },
   "source": [
    "Vamos a inspeccionar el [`.state_dict()`](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html) de nuestro modelo para ver qu√© tan cerca est√° nuestro modelo de los valores originales que establecimos para los pesos y el sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxXh73qj52L1",
    "outputId": "d79240f3-2f40-4f13-d413-763ae98b1ec7"
   },
   "outputs": [],
   "source": [
    "# Mostrando los par√°metros con los valores aprendidos\n",
    "print(\"El modelo aprendi√≥ los siguientes valores para pesos y sesgo:\")\n",
    "print(model_0.state_dict())\n",
    "print(\"\\nLos valores originales para pesos y sesgo fueron:\")\n",
    "print(f\"weights: {w}, bias: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNGqNC3D6cL4"
   },
   "source": [
    "### Haciendo predicciones con un modelo entrenado de PyTorch (inferencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5RJu5ay6TuH"
   },
   "source": [
    "\n",
    "\n",
    "Una vez que has entrenado un modelo, probablemente querr√°s hacer predicciones con √©l.\n",
    "\n",
    "Ya hemos visto un vistazo de esto en el c√≥digo de entrenamiento y prueba anterior, los pasos para hacerlo fuera del ciclo de entrenamiento/prueba son similares.\n",
    "\n",
    "Hay tres cosas que debes recordar al hacer predicciones (tambi√©n llamado realizar inferencia) con un modelo de PyTorch:\n",
    "\n",
    "1. Establecer el modelo en modo de evaluaci√≥n (`model.eval()`).\n",
    "2. Hacer las predicciones usando el administrador de contexto de modo de inferencia (`with torch.inference_mode(): ...`).\n",
    "3. Todas las predicciones deben hacerse con objetos en el mismo dispositivo (por ejemplo, datos y modelo solo en GPU o datos y modelo solo en CPU).\n",
    "\n",
    "Los dos primeros puntos aseguran que todos los c√°lculos y configuraciones √∫tiles que PyTorch usa tras bambalinas durante el entrenamiento, pero que no son necesarios para la inferencia, est√©n apagados (esto resulta en un c√°lculo m√°s r√°pido). Y el tercero asegura que no tendr√°s errores por cruzar dispositivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpe3h6KY6MPo",
    "outputId": "68178ce6-f709-4170-ce71-582fdf96a8a6"
   },
   "outputs": [],
   "source": [
    "# 1. Actviando el modo de evaluaci√≥n\n",
    "model_0.eval()\n",
    "\n",
    "# 2. Colocando el modelo en modo de inferencia\n",
    "with torch.inference_mode():\n",
    "  # 3. Aseg√∫rese de que los c√°lculos se realicen con el modelo y los datos en el mismo dispositivo;\n",
    "  # en nuestro caso, a√∫n no hemos configurado un c√≥digo independiente del dispositivo,\n",
    "  # por lo que nuestros datos y modelo est√°n en la CPU de forma predeterminada.\n",
    "\n",
    "  # model_0.to(device)\n",
    "  # X_test = X_test.to(device)\n",
    "\n",
    "  y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5cVVh3M6s_C"
   },
   "source": [
    "Hemos hecho algunas predicciones con nuestro modelo entrenado, ¬øc√≥mo se ven ahora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "_SFBPC_s6lME",
    "outputId": "f1d214b6-2d31-4080-f8ef-a00282c2a693"
   },
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWQIb8-9EPw2"
   },
   "source": [
    "## 5. Redes Neuronales (NNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD9z_jbiqhgG"
   },
   "source": [
    "### Clasificaci√≥n de Im√°genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4xv54OcEdzz"
   },
   "source": [
    "\n",
    "\n",
    "Un [problema de clasificaci√≥n](https://es.wikipedia.org/wiki/Clasificaci√≥n_estad√≠stica) implica predecir si algo es una cosa o otra.\n",
    "\n",
    "Por ejemplo, podr√≠as querer:\n",
    "\n",
    "| Tipo de problema | ¬øQu√© es? | Ejemplo |\n",
    "| ----- | ----- | ----- |\n",
    "| **Clasificaci√≥n binaria** | El objetivo puede ser una de dos opciones, por ejemplo, s√≠ o no | Predecir si una persona tiene o no enfermedad card√≠aca en funci√≥n de sus par√°metros de salud. |\n",
    "| **Clasificaci√≥n multi-clase** | El objetivo puede ser una de m√°s de dos opciones | Decidir si una foto es de comida, una persona o un perro. |\n",
    "| **Clasificaci√≥n multi-etiqueta** | El objetivo puede asignarse a m√°s de una opci√≥n | Predecir qu√© categor√≠as deben asignarse a un art√≠culo de Wikipedia (por ejemplo, matem√°ticas, ciencia y filosof√≠a). |\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1gLya_iLw3EdljxgQtqgqmrhn5zoOO7yt'>\n",
    "\n",
    "    \n",
    "La clasificaci√≥n, junto con la regresi√≥n (predecir un n√∫mero), es uno de los tipos m√°s comunes de problemas en *machine learning*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQkmNiqCEuBh"
   },
   "source": [
    "Al igual que en el escenario anterior, el \"esquema\" o flujo de trabajo que se sigue para la implementaci√≥n de modelos de aprendizaje autom√°tico particularmetne en PyTorch, inlcuso para un problema de clasificaci√≥n, es:\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1W1vuZFx0nYRbvqVdnHnOhfB-N6REpJgy'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huHhIz9sE0EP"
   },
   "source": [
    "Excepto que en lugar de intentar predecir una l√≠nea recta (predecir un n√∫mero, tambi√©n llamado problema de regresi√≥n), trabajaremos en un **problema de clasificaci√≥n**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SBEpdB6qmZu"
   },
   "source": [
    "### Arquitectura de una red neuronal para clasificaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTC20UsUE_5l"
   },
   "source": [
    "\n",
    "\n",
    "Antes de comenzar a escribir c√≥digo, veamos la arquitectura general de una red neuronal para clasificaci√≥n.\n",
    "\n",
    "| **Hiperpar√°metro** | **Clasificaci√≥n binaria** | **Clasificaci√≥n multicategor√≠a** |\n",
    "| --- | --- | --- |\n",
    "| **Forma de la capa de entrada** (`in_features`) | Igual al n√∫mero de caracter√≠sticas (por ejemplo, altura, peso, estado de fumador en la predicci√≥n de enfermedades card√≠acas) | Igual a la clasificaci√≥n binaria |\n",
    "| **Capa(s) oculta(s)** | Espec√≠fico al problema, m√≠nimo = 1, m√°ximo = ilimitado | Igual a la clasificaci√≥n binaria |\n",
    "| **Neuronas por capa oculta** | Espec√≠fico al problema, generalmente de 10 a 512 | Igual a la clasificaci√≥n binaria |\n",
    "| **Forma de la capa de salida** (`out_features`) | 1 (una clase u otra) | 1 por clase (por ejemplo, 3 para foto de comida, persona o perro) |\n",
    "| **Activaci√≥n de la capa oculta** | Usualmente [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) (unidad lineal rectificada), pero [puede ser muchas otras](https://es.wikipedia.org/wiki/Funci%C3%B3n_de_activaci%C3%B3n#Tabla_de_funciones_de_activaci%C3%B3n). | Igual a la clasificaci√≥n binaria |\n",
    "| **Activaci√≥n de la salida** | [Sigmoide](https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide) ([`torch.sigmoid`](https://pytorch.org/docs/stable/generated/torch.sigmoid.html) en PyTorch) | [Softmax](https://es.wikipedia.org/wiki/Funci%C3%B3n_softmax) ([`torch.softmax`](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) en PyTorch) |\n",
    "| **Funci√≥n de p√©rdida** | [Entrop√≠a cruzada binaria](https://es.wikipedia.org/wiki/Entrop%C3%ADa_cruzada#Funci%C3%B3n_de_p%C3%A9rdida_de_entrop%C3%ADa_cruzada_y_regresi%C3%B3n_log%C3%ADstica) ([`torch.nn.BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) en PyTorch) | Entrop√≠a cruzada ([`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) en PyTorch) |\n",
    "| **Optimizador** | [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) (descenso de gradiente estoc√°stico), [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) (ver [`torch.optim`](https://pytorch.org/docs/stable/optim.html) para m√°s opciones) | Igual a la clasificaci√≥n binaria |\n",
    "\n",
    "Por supuesto, esta lista de componentes de una red neuronal de clasificaci√≥n variar√° seg√∫n el problema con el que est√©s trabajando.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osCBF2Iiqs1T"
   },
   "source": [
    "###  Bibliotecas de visi√≥n por computadora en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13u-et-4FdTs"
   },
   "source": [
    "\n",
    "\n",
    "Antes de empezar a escribir c√≥digo, hablemos de algunas librer√≠as de visi√≥n por computadora en PyTorch que debes conocer.\n",
    "\n",
    "| M√≥dulo de PyTorch | ¬øQu√© hace? |\n",
    "| ----- | ----- |\n",
    "| [`torchvision`](https://pytorch.org/vision/stable/index.html) | Contiene conjuntos de datos, arquitecturas de modelos y transformaciones de im√°genes que suelen usarse para problemas de visi√≥n por computadora. |\n",
    "| [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) | Contiene ejemplos de conjuntos de datos de visi√≥n por computadora para una variedad de problemas, como clasificaci√≥n de im√°genes, detecci√≥n de objetos, creaci√≥n de descripciones de im√°genes, etc. Tambi√©n contiene [clases base para crear conjuntos de datos personalizados](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
    "| [`torchvision.models`](https://pytorch.org/vision/stable/models.html) | Este m√≥dulo contiene arquitecturas de modelos de visi√≥n por computadora bien optimizadas y com√∫nmente usadas en PyTorch; puedes usarlas con tus propios problemas. |\n",
    "| [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) | Frecuentemente, las im√°genes necesitan ser transformadas (convertidas en n√∫meros/procesadas/aumentadas) antes de ser usadas en un modelo; aqu√≠ se encuentran transformaciones comunes de im√°genes. |\n",
    "| [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) | Clase base para conjuntos de datos en PyTorch. |\n",
    "| [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data) | Crea un iterable en Python sobre un conjunto de datos (creado con `torch.utils.data.Dataset`). |\n",
    "\n",
    "> **Nota:** Las clases `torch.utils.data.Dataset` y `torch.utils.data.DataLoader` no son exclusivas para visi√≥n por computadora en PyTorch; son capaces de manejar muchos tipos diferentes de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQBscGKXqwta"
   },
   "source": [
    "### Obteniendo un conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNuAVxwLFuuL"
   },
   "source": [
    "Para comenzar a trabajar en un problema de visi√≥n por computadora, primero obtengamos un conjunto de datos de im√°genes.\n",
    "\n",
    "PyTorch tiene una gran cantidad de conjuntos de datos de visi√≥n por computadora comunes almacenados en `torchvision.datasets`.\n",
    "\n",
    "En este taller vamos a utilizar un conjunto de datos proveniente de la plataforma [Kaggle](https://www.kaggle.com/). Particularmente el conjunto de datos \"Traffic Signs Preprocessed\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I06KL7u3qLUa"
   },
   "source": [
    "### üìÇ Traffic Signs Preprocessed (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gemo4FEqG9qC"
   },
   "source": [
    "El _dataset_ **Traffic Signs Preprocessed** es una versi√≥n ya procesada y normalizada de datos de se√±ales de tr√°nsito.  \n",
    "Fue creado por **Valentyn Sichkar** y est√° disponible en [Kaggle](https://www.kaggle.com/datasets/valentynsichkar/traffic-signs-preprocessed).\n",
    "\n",
    "#### üìä Caracter√≠sticas principales\n",
    "- Contiene aproximadamente **87,000 ejemplos de entrenamiento**.\n",
    "- Est√° dividido en **train, validation y test**, en formato **Pickle**.\n",
    "- Incluye **43 clases** diferentes de se√±ales de tr√°nsito (ej. l√≠mites de velocidad, advertencias, ceda el paso).\n",
    "- Disponible en **RGB** y en **escala de grises**.\n",
    "- Las im√°genes han sido **normalizadas** y ajustadas para facilitar su uso en redes neuronales.\n",
    "\n",
    "#### ‚ö†Ô∏è Limitaciones\n",
    "- Las im√°genes no siempre son de tama√±o fijo ni con fondo completamente limpio.\n",
    "- Posible **desbalance de clases**.\n",
    "- Puede requerir adaptaci√≥n adicional (redimensionado o centrado) para ciertos modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vGFxoYKgaX6"
   },
   "source": [
    "#### Cargando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGya6kWZOYNt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "def download_from_drive(ID_PUBLICO_DRIVE, NOMBRE_DESTINO):\n",
    "  # Ejecutar la descarga\n",
    "  try:\n",
    "      print(f\"Intentando descargar el ID: {ID_PUBLICO_DRIVE}\")\n",
    "      gdown.download(id=ID_PUBLICO_DRIVE, output=NOMBRE_DESTINO, quiet=False)\n",
    "\n",
    "      if os.path.exists(NOMBRE_DESTINO):\n",
    "          print(f\"\\n‚úÖ ¬°Descarga exitosa! Archivo guardado como: {NOMBRE_DESTINO}\")\n",
    "          # Si es un ZIP, puedes descomprimirlo inmediatamente\n",
    "          if NOMBRE_DESTINO.endswith('.zip'):\n",
    "              !unzip {NOMBRE_DESTINO} -d /content/some_imgs\n",
    "              print(\"Archivo descomprimido.\")\n",
    "              !rm /content/{NOMBRE_DESTINO}\n",
    "      else:\n",
    "           print(\"\\n‚ö†Ô∏è Advertencia: No se pudo verificar la descarga. Revisa el ID y los permisos.\")\n",
    "\n",
    "  except Exception as e:\n",
    "      print(f\"\\n‚ùå Error durante la descarga: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gM-PQTkHO2Ho",
    "outputId": "c9ab67dc-7054-4a70-e5ed-d7a9d79a8c7a"
   },
   "outputs": [],
   "source": [
    "# --- CONFIGURACI√ìN ---\n",
    "#Names\n",
    "ID_PUBLICO_DRIVE = '1HX4L3YwRwlnK8Fkx7nDaaFh4FKisBjUR'\n",
    "NOMBRE_DESTINO = 'label_names.csv' # El nombre que tendr√° el archivo al descargarse\n",
    "download_from_drive(ID_PUBLICO_DRIVE, NOMBRE_DESTINO)\n",
    "\n",
    "#Datos de validacion\n",
    "ID_PUBLICO_DRIVE = '1cvX1vmUICThgbcAJohcwT_9PEMCkRXR3'\n",
    "NOMBRE_DESTINO = 'valid.pickle' # El nombre que tendr√° el archivo al descargarse\n",
    "download_from_drive(ID_PUBLICO_DRIVE, NOMBRE_DESTINO)\n",
    "\n",
    "#Datos de entrenamiento\n",
    "ID_PUBLICO_DRIVE = '19KnZKR8viJjJebWgmzyylu5E0RqAnemq'\n",
    "NOMBRE_DESTINO = 'train.pickle' # El nombre que tendr√° el archivo al descargarse\n",
    "download_from_drive(ID_PUBLICO_DRIVE, NOMBRE_DESTINO)\n",
    "\n",
    "#Datos de prueba\n",
    "ID_PUBLICO_DRIVE = '1Cv56ilpPxf2CHF8ZF5ImD3VKha2MdR_b'\n",
    "NOMBRE_DESTINO = 'test.pickle' # El nombre que tendr√° el archivo al descargarse\n",
    "download_from_drive(ID_PUBLICO_DRIVE, NOMBRE_DESTINO)\n",
    "\n",
    "# No descomentar Comando para eliminar la carpete\n",
    "#!rm -rf /content/some_imgs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQmKB2jDaw8L"
   },
   "outputs": [],
   "source": [
    "!mkdir traffic_signs\n",
    "!mv label_names.csv /content/traffic_signs\n",
    "!mv train.pickle /content/traffic_signs\n",
    "!mv test.pickle /content/traffic_signs\n",
    "!mv valid.pickle /content/traffic_signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r237tynBTXWl"
   },
   "source": [
    "#### Generando los conjuntos de Entrenamiento, Validaci√≥n y Prueba (_train_, _val_, _test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYF5yfTwJiuo",
    "outputId": "167138d4-fe74-4643-8d82-0187020ef3e1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "\n",
    "# Ruta de los datos descargados\n",
    "data_dir = \"./traffic_signs\"\n",
    "\n",
    "# --- Funci√≥n para cargar archivos pickle ---\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"latin1\")\n",
    "    return data\n",
    "\n",
    "# --- Funci√≥n para leer los nombres de las clases ---\n",
    "def label_text(file):\n",
    "    # Definici√≥n de lista para guardar etiquetas en orden de 0 a 42\n",
    "    label_list = []\n",
    "\n",
    "    # Abrir archivo 'csv' y obtener las etiquetas de las im√°genes\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # Pasando por todas las filas\n",
    "        for row in reader:\n",
    "            # Agregar de cada fila la segunda columna con el nombre de la etiqueta\n",
    "            label_list.append(row[1])\n",
    "        # Eliminar el primer elemento de la lista porque es el nombre de la columna\n",
    "        del label_list[0]\n",
    "    # Devolviendo la lista de resultados\n",
    "    return label_list\n",
    "\n",
    "\n",
    "# Cargar train, valid, test\n",
    "train_data = load_pickle(os.path.join(data_dir, \"train.pickle\"))\n",
    "valid_data = load_pickle(os.path.join(data_dir, \"valid.pickle\"))\n",
    "test_data  = load_pickle(os.path.join(data_dir, \"test.pickle\"))\n",
    "\n",
    "class_names = label_list = label_text(os.path.join(data_dir, \"label_names.csv\"))\n",
    "\n",
    "# Extraer features y labels\n",
    "X_train, y_train = train_data['features'], train_data['labels']\n",
    "X_valid, y_valid = valid_data['features'], valid_data['labels']\n",
    "X_test,  y_test  = test_data['features'],  test_data['labels']\n",
    "\n",
    "print(\"Tama√±o de entrenamiento:\", X_train.shape)\n",
    "print(\"Tama√±o de validaci√≥n:\", X_valid.shape)\n",
    "print(\"Tama√±o de prueba:\", X_test.shape)\n",
    "\n",
    "print(\"N√∫mero de clases:\", len(class_names))\n",
    "print(\"Nombre de las clases:\", class_names)\n",
    "\n",
    "# --- Convertir a escala de grises ---\n",
    "# Usamos la expresion luminancia: Y = 0.299R + 0.587G + 0.114B\n",
    "def rgb2gray(images):\n",
    "    return (\n",
    "        0.299 * images[:,:,:,0] +\n",
    "        0.587 * images[:,:,:,1] +\n",
    "        0.114 * images[:,:,:,2]\n",
    "    )\n",
    "\n",
    "X_train_gray = rgb2gray(X_train)[..., None]  # a√±adir canal\n",
    "X_valid_gray = rgb2gray(X_valid)[..., None]\n",
    "X_test_gray  = rgb2gray(X_test)[..., None]\n",
    "\n",
    "print(\"Nuevo shape (escala de grises) entrenamiento:\", X_train_gray.shape)\n",
    "print(\"Nuevo shape (escala de grises) validacio:\", X_valid_gray.shape)\n",
    "print(\"Nuevo shape (escala de grises) prueba:\", X_test_gray.shape)\n",
    "\n",
    "# --- Convertir a tensores de PyTorch (N, C, H, W) ---\n",
    "X_train_t = torch.tensor(X_train_gray, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_valid_t = torch.tensor(X_valid_gray, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "y_valid_t = torch.tensor(y_valid, dtype=torch.long)\n",
    "\n",
    "X_test_t  = torch.tensor(X_test_gray,  dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "y_test_t  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "# Crear TensorDatasets y DataLoaders\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "valid_dataset = TensorDataset(X_valid_t, y_valid_t)\n",
    "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "Yh5qaR1LJriO",
    "outputId": "5a04ccc9-c58a-49f4-d59a-eb98dbfe072e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Funci√≥n para mostrar imagen en escala de grises ---\n",
    "def show_image_gray(index, dataset=X_train_gray, labels_id=y_train):\n",
    "    \"\"\"Muestra una imagen en escala de grises y su etiqueta\"\"\"\n",
    "    img = dataset[index].squeeze()  # quitar canal extra\n",
    "    label = class_names[labels_id[index]]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"Etiqueta: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo: mostrar la primera imagen\n",
    "index = 500 # Este √≠ndice pude ser un valor entre 0 y 34,798\n",
    "show_image_gray(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ33Ty0wMM-9"
   },
   "source": [
    "Veamos algunas m√°s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "id": "Qntd6zdQKPid",
    "outputId": "d3d58665-830b-4e22-b99f-9252b04968e3"
   },
   "outputs": [],
   "source": [
    "# Graficando m√°s im√°genes\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "rows, cols = 4, 4\n",
    "\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(X_train_gray), size=[1]).item()\n",
    "    img, label = X_train_gray[random_idx], class_names[y_train_t[random_idx]]\n",
    "\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(label, fontsize=7)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KWJ_NUVTK0T"
   },
   "source": [
    "### Preparando los datos. Uso de *DataLoader*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_igLQiS3UC_e"
   },
   "source": [
    "Ahora tenemos un conjunto de datos listo para usar.\n",
    "\n",
    "El siguiente paso es prepararlo con un [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset), o `DataLoader` para abreviar.\n",
    "\n",
    "El `DataLoader`:\n",
    "- Ayuda a cargar datos en un modelo.\n",
    "\n",
    "- Es usado tanto en entrenamiento como en inferencia.\n",
    "\n",
    "- Convierte un `Dataset` grande en un \"iterable\" de Python de partes m√°s peque√±as.\n",
    "\n",
    "  - Estas partes m√°s peque√±as se llaman ***batches*** o ***mini-batches*** y se pueden establecer con el par√°metro `batch_size`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAHd0UkCTsQ7"
   },
   "source": [
    "#### Lotes (_Batches_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hchGG3gPT-7c"
   },
   "source": [
    "¬øPor qu√© usar lotes (*batches*)?\n",
    "\n",
    "- Porque es m√°s eficiente computacionalmente.\n",
    "\n",
    "- En un mundo ideal, podr√≠as hacer la pasada hacia adelante y la pasada hacia atr√°s con todos tus datos a la vez. Pero una vez que comienzas a usar conjuntos de datos realmente grandes, a menos que tengas poder de c√≥mputo infinito, es m√°s f√°cil dividirlos en lotes (*batches*).\n",
    "\n",
    "- Su uso le da a tu modelo m√°s oportunidades de mejorar.\n",
    "\n",
    "Con **mini-batches** (peque√±as porciones de los datos), el descenso de gradiente se realiza m√°s veces por √©poca (una vez por *mini-batches* en lugar de una vez por √©poca).\n",
    "\n",
    "¬øQu√© tama√±o de *batch* es bueno?\n",
    "\n",
    "[32 es un buen lugar para comenzar](https://twitter.com/ylecun/status/989610208497360896?s=20&t=N96J_jotN--PYuJk2WcjMw) para una buena cantidad de problemas.\n",
    "\n",
    "Pero como este es un valor que puedes ajustar (un **hiperpar√°metro**), puedes probar diferentes valores, aunque generalmente se utilizan potencias de 2 con m√°s frecuencia (por ejemplo, 32, 64, 128, 256, 512).\n",
    "\n",
    "![ejemplo de c√≥mo se ve un conjunto de datos en lotes](https://drive.google.com/uc?id=1r3lgFpU7ZMxb6DIOQpgi-T3gmofCkjsV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NymK5OBuUhEz"
   },
   "source": [
    "Vamos a crear `DataLoader`'s para nuestros conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFis8PCVHiyE",
    "outputId": "2775cca3-e340-4ca2-8926-9ee16d184110"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Instanciando el tama√±o del \"batch\" (hiperpar√°metro)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# Convierte conjuntos de datos en datos \"iterables\"\n",
    "train_dataloader = DataLoader(train_dataset, # dataset\n",
    "    batch_size=BATCH_SIZE, # Num de \"batches\"\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Revisando lo que se ha generado\n",
    "print(f\"Dataloaders: {train_dataloader, valid_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of train dataloader: {len(valid_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaZvxCDcdgrs",
    "outputId": "236f16c8-7056-4c5b-c083-36c66a85f4ff"
   },
   "outputs": [],
   "source": [
    "# Vea lo que hay dentro del \"dataloader\" de los datos de entrenamiento\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cD9-dn1n-3K"
   },
   "source": [
    "### Construyendo el modelo (NN) para clasificaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcdB3ExYc-jv"
   },
   "source": [
    "\n",
    "\n",
    "Con los datos cargados y preparados, es hora de construir un **modelo base** utilizando `nn.Module`.\n",
    "\n",
    "Nuestro modelo base consistir√° en dos capas [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
    "\n",
    "Debido a que estamos trabajando con datos de im√°genes, vamos a usar una capa diferente para comenzar.\n",
    "\n",
    "Y esa es la capa [`nn.Flatten()`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html).\n",
    "\n",
    "- `nn.Flatten()` comprime las dimensiones de un tensor en un solo vector.\n",
    "\n",
    "Particularmente el modelo a generar es:\n",
    "\n",
    "\n",
    "![modelo base](https://drive.google.com/uc?id=1ZUvLUa81OPqQTx2fdEDbH5P4DVomcJWA)\n",
    "\n",
    "*Modelo Base*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYaFcmKlcyRh",
    "outputId": "dd3f2d7f-a13c-4ade-9a35-a2dc3a88b12e"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Creando una capa (layer) tipo \"flatten\"\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Obteniendo una muestra\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# \"Aplanando\" la muestra\n",
    "output = flatten_model(x)\n",
    "\n",
    "# Mostrando la salida\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRUy4dGQeWFa"
   },
   "source": [
    "La capa `nn.Flatten()` transform√≥ el dato de la forma `[color_channels, height, width]` a `[color_channels, height*width]`.\n",
    "\n",
    "¬øPor qu√© hacer esto?\n",
    "\n",
    "Porque ahora hemos convertido nuestros datos de p√≠xeles de dimensiones de altura y ancho en un **vector de caracter√≠sticas** largo.\n",
    "\n",
    "Y las capas `nn.Linear()` prefieren que sus entradas est√©n en forma de vectores de caracter√≠sticas.\n",
    "\n",
    "\n",
    "Ahora, vamos a crear el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzTXHDOuekGX"
   },
   "source": [
    "#### Creando el modelo para clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "Y2YfQbX3ZZ_D",
    "outputId": "88a3bb30-f3d1-4f03-88ed-4d53e24957e0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrow\n",
    "\n",
    "# Define layer labels\n",
    "layers = [\n",
    "    (\"Input\", \"1√ó32√ó32\"),\n",
    "    (\"Flatten\", \"‚Üí 1024\"),\n",
    "    (\"Linear\", \"1024 ‚Üí 10\"),\n",
    "    (\"Linear\", \"10 ‚Üí 10\"),\n",
    "    (\"Output\", \"10 classes\")\n",
    "]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Position parameters\n",
    "x_start = 0.1\n",
    "y = 0.5\n",
    "box_width = 0.15\n",
    "box_height = 0.2\n",
    "spacing = 0.08\n",
    "\n",
    "# Draw boxes and arrows\n",
    "for i, (name, shape) in enumerate(layers):\n",
    "    x = x_start + i * (box_width + spacing)\n",
    "\n",
    "    # Draw layer box\n",
    "    box = FancyBboxPatch((x, y - box_height/2), box_width, box_height,\n",
    "                         boxstyle=\"round,pad=0.02\",\n",
    "                         edgecolor=\"black\", facecolor=\"#a8dadc\")\n",
    "    ax.add_patch(box)\n",
    "\n",
    "    # Add text\n",
    "    ax.text(x + box_width/2, y + 0.03, name, ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.text(x + box_width/2, y - 0.08, shape, ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    # Draw arrow (except after last box)\n",
    "    if i < len(layers) - 1:\n",
    "        ax.add_patch(FancyArrow(\n",
    "            x + box_width, y, spacing - 0.02, 0,\n",
    "            width=0.005, head_width=0.03, head_length=0.02,\n",
    "            length_includes_head=True, color=\"gray\"))\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.xlim(0, x_start + len(layers) * (box_width + spacing))\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Estructura del Modelo\", fontsize=12, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT_G4zDEdn-C"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NNModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Modelo\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # neural networks like their inputs in vector form\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = N√∫mero de \"caracter√≠sticas\" en una muestra de datos (1024 p√≠xeles))\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52ADGI85exLj"
   },
   "source": [
    "Tenemos una clase del modelo que podemos usar, ahora instanciemos un modelo.\n",
    "\n",
    "Necesitaremos establecer los siguientes par√°metros:\n",
    "* `input_shape=1024` - esta es la cantidad de caracter√≠sticas que entran en el modelo; en nuestro caso, es una por cada p√≠xel en la imagen objetivo (32 p√≠xeles de alto por 32 p√≠xeles de ancho = 1024 caracter√≠sticas).\n",
    "* `hidden_units=10` - n√∫mero de unidades/neuronas en la(s) capa(s) oculta(s); este n√∫mero podr√≠a ser el que prefieras, pero para mantener el modelo peque√±o, comenzaremos con `10`.\n",
    "* `output_shape=` N√∫mero de clases - como estamos trabajando con un problema de clasificaci√≥n multiclase, necesitamos una neurona de salida por clase en nuestro conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTWd9_jLet8N",
    "outputId": "255135f9-f629-45c5-963d-a5fa75eafc18"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Agregue los valores faltantes:\n",
    "#-----------\n",
    "entrada_tamanio  =\n",
    "unidades_ocultas =\n",
    "num_clases       =\n",
    "#-----------\n",
    "\n",
    "# Need to setup model with input parameters\n",
    "model_0 = NNModelV0(input_shape=entrada_tamanio, # one for every pixel (32x32)\n",
    "    hidden_units=unidades_ocultas, # how many units in the hidden layer\n",
    "    output_shape=num_clases # one for every class\n",
    ")\n",
    "\n",
    "model_0.to(\"cpu\") # keep model on CPU to begin with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5eH9VKtf7rb"
   },
   "source": [
    "####  Configurando la funci√≥n de p√©rdida, el optimizador y las m√©tricas de evaluaci√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-g78QeS2fZSa"
   },
   "outputs": [],
   "source": [
    "# Calcular la precisi√≥n (una m√©trica de clasificaci√≥n)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() Calcula d√≥nde son iguales dos tensores\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txIj11oPgEjy"
   },
   "outputs": [],
   "source": [
    "# Configuraci√≥n de la funci√≥n de p√©rdida y optimizador\n",
    "loss_fn = nn.CrossEntropyLoss() # Esto tambi√©n se llama \"criterio\"/\"funci√≥n de costo\" en algunos lugares.\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxAbPnUygNSz"
   },
   "source": [
    "####  Creaci√≥n de una funci√≥n para cronometrar nuestros experimentos\n",
    "\n",
    "Es decir, vamos a crear una funci√≥n de cronometraje para medir el tiempo que toma entrenar nuestro modelo.\n",
    "\n",
    "Nuestra funci√≥n de cronometraje importar√° la [funci√≥n `timeit.default_timer()`](https://docs.python.org/3/library/timeit.html#timeit.default_timer) del m√≥dulo [`timeit` de Python](https://docs.python.org/3/library/timeit.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xhjb3Cl3gKIk"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format).\n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PBSOljLg53P"
   },
   "source": [
    "#### Creaci√≥n del ciclo de entrenamiento un modelo en *batches* de datos\n",
    "\n",
    "Parece que tenemos todas las piezas del rompecabezas listas: un cron√≥metro, una funci√≥n de p√©rdida, un optimizador, un modelo y, lo m√°s importante, algunos datos.\n",
    "\n",
    "Ahora vamos a crear el ciclo de entrenamiento y el de prueba para entrenar y evaluar nuestro modelo.\n",
    "\n",
    "Usaremos los mismos pasos anteriores, aunque como ahora nuestros datos est√°n en forma de *batches*, a√±adiremos otro ciclo para recorrerlos.\n",
    "\n",
    "- Nuestros *batches* de datos est√°n contenidos en nuestros `DataLoader`s: `train_dataloader` y `test_dataloader` para las divisiones de entrenamiento y prueba, respectivamente.\n",
    "\n",
    "- Dado que estamos usando `BATCH_SIZE=32`, nuestros *batches* tienen 32 muestras de im√°genes y objetivos.\n",
    "\n",
    "- Y como estamos iterando sobre *batches*, nuestra p√©rdida y m√©tricas de evaluaci√≥n se calcular√°n **por batch** en lugar de hacerlo en todo el conjunto de datos.\n",
    "\n",
    "- Esto significa que tendremos que dividir nuestros valores de p√©rdida y precisi√≥n por la cantidad de *batches* en el `dataloader` correspondiente a cada conjunto de datos.\n",
    "\n",
    "Entocnes, desglosando:\n",
    "1. Ciclo a trav√©s de las √©pocas.\n",
    "2. Cilco a trav√©s de los *batches* de entrenamiento, realiza los pasos de entrenamiento y calcula la p√©rdida de entrenamiento *por batch*.\n",
    "3. Ciclo a trav√©s de los *batches* de prueba, realiza los pasos de prueba y calcula la p√©rdida de prueba por *batch*.\n",
    "4. Imprime lo que est√° sucediendo.\n",
    "5. Cronometra todo (no es necesario pero es conveniente).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5c70c445f0984b6687f6d534c319ac11",
      "5147fe5bc481412eb8259e571a8275bc",
      "46ec982148894ff6acac2bbcc736f93e",
      "9c5faa63edea44d8b103cff5e78868ab",
      "3120d5d1f94a4bf2947919df73c8adf4",
      "2abe284e2ad043b384bdc56402e64133",
      "230c09e670784b659a78f9361fbabc44",
      "88858444534b40688acdc548f8ecfc7d",
      "f87a7ad687324be4acde2550d09b452d",
      "f98a123a8c864c69a28e1fefd14b7e1a",
      "8a272f923c184857b61bb4a28fda7510"
     ]
    },
    "id": "J05mvroggRi-",
    "outputId": "b76d1513-675f-4dc8-ece5-0d07cf5dd3c1"
   },
   "outputs": [],
   "source": [
    "# tqdm Para mostrar una barra de progreso\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Establezca la semilla e inicie el temporizador.\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Establezca el n√∫mero de √©pocas (lo mantendremos peque√±o para tiempos de entrenamiento m√°s r√°pidos)\n",
    "epochs = 7\n",
    "\n",
    "# Crear el ciclo de entrenamiento y prueba\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    # -----------------------\n",
    "    ### Entrenamiento\n",
    "    train_loss = 0\n",
    "    # Ciclo para recorrer los \"batches\" de entrenamiento\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        # 1. \"Forward pass\"\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calcular p√©rdida (por batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # Suma acumulativamente la p√©rdida por √©poca\n",
    "\n",
    "        # 3. Optimizador - poniendo los gradientes a cero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. \"Loss backward\"\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. \"Optimizer step\"\n",
    "        optimizer.step()\n",
    "\n",
    "        # Imprimiendo cu√°ntas muestras se han visto\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # p√©rdida promedio por bacth por √©poca\n",
    "    train_loss /= len(train_dataloader)\n",
    "    # -----------------------\n",
    "\n",
    "    # -----------------------\n",
    "    ### Probando\n",
    "    # Configurar variables para sumar de forma acumulativa la p√©rdida y la precisi√≥n\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # X, y en test_dataloader:\n",
    "        for X, y in valid_dataloader:\n",
    "            # 1. \"Forward pass\"\n",
    "            test_pred = model_0(X)\n",
    "\n",
    "            # 2. Calculando la p√©rdida acumulada (loss accumulatively)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "            # 3. Calcular la precisi√≥n (los valores predichos deben ser iguales a y_true)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Los c√°lculos sobre las m√©tricas de prueba deben realizarse dentro de torch.inference_mode()\n",
    "        # Dividiendo la p√©rdida total por la longitud del \"dataloader\" de datos de pruebas (por batch)\n",
    "        test_loss /= len(valid_dataloader)\n",
    "\n",
    "        # Dividiendo la precisi√≥n total por la longitud del \"dataloader\" de datos de prueba (por batch)\n",
    "        test_acc /= len(valid_dataloader)\n",
    "\n",
    "    ## Mostrando la evoluci√≥n\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "# Calculando el tiempo de entrenamiento\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YrZG_GTq61S"
   },
   "source": [
    "### Haciendo predicciones y obteniendo los resultados del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdvp9vEKj7-u"
   },
   "source": [
    "Dado que vamos a construir varios modelos, es una buena idea escribir algo de c√≥digo para evaluarlos todos de manera similar.\n",
    "\n",
    "En concreto, vamos a crear una funci√≥n que reciba un modelo entrenado, un `DataLoader`, una funci√≥n de p√©rdida y una funci√≥n de precisi√≥n.\n",
    "\n",
    "La funci√≥n utilizar√° el modelo para hacer predicciones sobre los datos en el `DataLoader` y luego podremos evaluar esas predicciones utilizando la funci√≥n de p√©rdida y la funci√≥n de precisi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFrV4krSh7gP",
    "outputId": "ee4173a8-c9e9-4107-8e3d-ba533abc922d"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Hacer predicciones con el modelo\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Acumular los valores de p√©rdida y precisi√≥n por batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                                y_pred=y_pred.argmax(dim=1)) # Para la precisi√≥n, se necesitan las etiquetas de predicci√≥n (logits -> pred_prob -> pred_labels)\n",
    "\n",
    "        # Loss y exactitud (acc) por batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calcular los resultados del modelo 0 en el conjunto de datos de prueba\n",
    "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn)\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qbZmdTLlULi"
   },
   "source": [
    "### Modelo con no linealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi7TAqcqlQ9h"
   },
   "source": [
    "- Para este modelo trataresmo de usar el GPU; sin embargo, esto solo ser√° posible (usar el GPU) colab nos otorga una unidad de GPU.\n",
    "\n",
    "- Lo haremos recreando un modelo similar al anterior, pero esta vez pondremos funciones no lineales (`nn.ReLU()`) entre cada capa lineal.\n",
    "\n",
    "- PyTorch tiene un mont√≥n de [funciones de activaci√≥n no lineales ya preparadas](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity).\n",
    "\n",
    "- Una de las m√°s comunes y de mejor rendimiento es [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) (unidad lineal rectificada, [`torch.nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "m3LUhdnu4rDW",
    "outputId": "4aa84331-baf9-43d3-a091-e85e203b4af6"
   },
   "outputs": [],
   "source": [
    "# Create a range of input values (from -10 to 10)\n",
    "x = torch.linspace(-10, 10, 100)\n",
    "relu = nn.ReLU()      # ReLU activation function\n",
    "y = relu(x)                 # Apply ReLU to each value\n",
    "\n",
    "# Plot ReLU\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(x, y, label='ReLU(x) = max(0, x)', color='blue')\n",
    "plt.axhline(0, color='black', linewidth=0.8)\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.title('Rectified Linear Unit (ReLU)')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-lQZTq65OGW"
   },
   "source": [
    "| Concepto      | Descripci√≥n                                                                                         |\n",
    "| ------------- | --------------------------------------------------------------------------------------------------- |\n",
    "| **Nombre**    | Rectified Linear Unit (ReLU)                                                                        |\n",
    "| **Expresi√≥n**   | ( f(x) = \\max(0, x) )                                                                               |\n",
    "| **Efecto**    | Introduce no linealidad y permite aprender funciones complejas                                      |\n",
    "| **Beneficio** | Acelera la convergencia y evita el problema del gradiente desvanecido (comparado con sigmoide/tanh) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "qGiqEt362zCl",
    "outputId": "52695b5b-7695-423f-bedb-7e8eb9faf203"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrow\n",
    "\n",
    "# Define layer labels\n",
    "layers = [\n",
    "    (\"Input\", \"1√ó32√ó32\"),\n",
    "    (\"Flatten\", \"‚Üí 1024\"),\n",
    "    (\"Linear\", \"1024 ‚Üí 10\"),\n",
    "    (\"ReLU\", \"\"),\n",
    "    (\"Linear\", \"10 ‚Üí 10\"),\n",
    "    (\"ReLU\", \"\"),\n",
    "    (\"Output\", \"10 classes\")\n",
    "]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Position parameters\n",
    "x_start = 0.1\n",
    "y = 0.5\n",
    "box_width = 0.15\n",
    "box_height = 0.2\n",
    "spacing = 0.08\n",
    "\n",
    "# Draw boxes and arrows\n",
    "for i, (name, shape) in enumerate(layers):\n",
    "    x = x_start + i * (box_width + spacing)\n",
    "\n",
    "    # Draw layer box\n",
    "    box = FancyBboxPatch((x, y - box_height/2), box_width, box_height,\n",
    "                         boxstyle=\"round,pad=0.02\",\n",
    "                         edgecolor=\"black\", facecolor=\"#a8dadc\")\n",
    "    ax.add_patch(box)\n",
    "\n",
    "    # Add text\n",
    "    ax.text(x + box_width/2, y + 0.03, name, ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.text(x + box_width/2, y - 0.08, shape, ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    # Draw arrow (except after last box)\n",
    "    if i < len(layers) - 1:\n",
    "        ax.add_patch(FancyArrow(\n",
    "            x + box_width, y, spacing - 0.02, 0,\n",
    "            width=0.005, head_width=0.03, head_length=0.02,\n",
    "            length_includes_head=True, color=\"gray\"))\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.xlim(0, x_start + len(layers) * (box_width + spacing))\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Estructura del Modelo\", fontsize=12, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B8ZvlUhjmA9g",
    "outputId": "7572c85a-72e0-497a-f386-abb1fcb90780"
   },
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yrXtqCHkFf-"
   },
   "outputs": [],
   "source": [
    "# Crear un modelo con capas lineales y no lineales\n",
    "class NNModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_stack = nn.Sequential(\n",
    "          #-----------------\n",
    "          # Agregue su c√≥digo aqu√≠\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          #-----------------\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS1jq2fQliug"
   },
   "source": [
    "Ahora vamos a instanciarlo con las mismas configuraciones que usamos antes.\n",
    "\n",
    "Necesitaremos:\n",
    "- **`input_shape=1024`** (igual al n√∫mero de caracter√≠sticas de nuestros datos de imagen),\n",
    "- **`hidden_units=10`** (empezando peque√±o, igual que nuestro modelo base),\n",
    "- **`output_shape=` Numero de clases** (una unidad de salida por clase).\n",
    "\n",
    "> **Nota:** Observa c√≥mo hemos mantenido la mayor√≠a de las configuraciones de nuestro modelo iguales, excepto por un cambio: agregar capas no lineales. Esta es una pr√°ctica est√°ndar para realizar una serie de experimentos en machine learning: cambia una cosa y observa qu√© sucede, luego hazlo una vez m√°s, otra vez, otra vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKPyA8l2lfje",
    "outputId": "3d6761ba-5287-4a10-f4b5-fb5158d26b9e"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Agregue los valores faltantes:\n",
    "#-----------\n",
    "entrada_tamanio  =\n",
    "unidades_ocultas =\n",
    "num_clases       =\n",
    "#-----------\n",
    "\n",
    "\n",
    "model_1 = NNModelV1(input_shape=entrada_tamanio, # number of input features\n",
    "    hidden_units=unidades_ocultas,\n",
    "    output_shape=num_clases # number of output classes desired\n",
    ").to(device) # send model to GPU if it's available\n",
    "\n",
    "next(model_1.parameters()).device # check model device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AleDs398mMOS"
   },
   "source": [
    "Como de costumbre, configuraremos una funci√≥n de p√©rdida, un optimizador y una m√©trica de evaluaci√≥n (podr√≠amos utilizar m√∫ltiples m√©tricas de evaluaci√≥n, pero por ahora nos quedaremos con la exactitud (*accuracy*))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcYIA2h7mH9n"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1n2xuKgmVfZ"
   },
   "source": [
    "#### Haciendo funciones a los cilcos de entrenamiento y prueba\n",
    "\n",
    "Hasta ahora hemos estado escribiendo ciclos de entrenamiento y prueba una y otra vez.\n",
    "\n",
    "Escrib√°moslos de nuevo, pero esta vez los pondremos en funciones para que puedan ser llamados una y otra vez.\n",
    "\n",
    "Y como ahora estamos usando un c√≥digo independiente del dispositivo, nos aseguraremos de llamar a `.to(device)` en nuestros tensores de caracter√≠sticas (`X`) y de etiquetas (`y`).\n",
    "\n",
    "Para el ciclo de entrenamiento, crearemos una funci√≥n llamada `train_step()` que recibe un modelo, un `DataLoader`, una funci√≥n de p√©rdida y un optimizador.\n",
    "\n",
    "El ciclo de prueba ser√° similar, pero se llamar√° `test_step()` y recibir√° un modelo, un `DataLoader`, una funci√≥n de p√©rdida y una funci√≥n de evaluaci√≥n.\n",
    "\n",
    "> **Nota:** Dado que estas son funciones, puedes personalizarlas de la manera que desees. Lo que estamos creando aqu√≠ puede considerarse funciones b√°sicas de entrenamiento y prueba para nuestro caso espec√≠fico de clasificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qv9dOq2dmRsv"
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDnzxIIamsKx"
   },
   "source": [
    "¬°Ahora que tenemos algunas funciones para entrenar y probar nuestro modelo, vamos a ejecutarlas!\n",
    "\n",
    "Lo haremos dentro de otro ciclo para cada √©poca. De esa manera, para cada √©poca, pasamos por un paso de entrenamiento y un paso de prueba.\n",
    "\n",
    "> **Nota:** Puedes personalizar la frecuencia con la que haces un paso de prueba. Algunas veces las personas lo hacen cada cinco √©pocas, diez √©pocas o, en nuestro caso, cada √©poca.\n",
    "\n",
    "Tambi√©n vamos a medir el tiempo para ver cu√°nto tarda nuestro c√≥digo en ejecutarse en la GPU (si est√° disponible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674,
     "referenced_widgets": [
      "5d0b1568eb6f44b8a67acb7c210a9e08",
      "b603f05217eb49f6b70edf297f0b7c21",
      "0d1802ef3e3b4f7a90b866e01b653f5e",
      "7a307cc6b067416fa14f3453cb30465f",
      "45f67fd1ef0c4eb79655c5117ac35c79",
      "bc80e987dda547d2994f76c52617b35f",
      "1f5adb0772e841daabb4cff70fd2ddd8",
      "90d62187c31f4dc7bac22e4d9d9e6ff8",
      "89c3a632f14b4e2ab976d07b575e48a5",
      "778f385c4755471e94b02bc59d179365",
      "4b1d44a2eedc4c3380dd457f628fb4b7"
     ]
    },
    "id": "U9IRlacFmpXz",
    "outputId": "13ad54b4-c0cc-4a08-d24c-c9632f39606d"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Midiento el tiempo\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 7\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "\n",
    "    train_step(data_loader=train_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "\n",
    "    test_step(data_loader=valid_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SiYB9qLnU4X"
   },
   "source": [
    "Podemos evaluar nuestro `model_1` entrenado usando nuestra funci√≥n `eval_model()` y ver c√≥mo ha ido. Sin embargo, tomemso en cuenta que hemos decidido utilzia el GPU (si est√° disponible), lo que implica que los datos y el modelo est√°n ah√≠, pero la funci√≥n de evalauci√≥n utiliza los datos alojados en el CPU, entonces, si el GPU est√° disponible, tendr√≠amos un error, por lo tanto, es necesario hacer una modificaci√≥n a la funcion `eval_model()` para que tome en cuenta el dispositivo en donde se est√°n analizando los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWqyPvbbnBx7",
    "outputId": "23158bfd-d37e-4592-b2a2-979bee873f0f"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluates a given model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Enviar datos al dispositivo de destino\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Loss y acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "\n",
    "# Calculate model 1 results with device-agnostic code\n",
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yURiRdj0nlm_"
   },
   "source": [
    "Comparando contra el primer modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0TrY_VAndsh",
    "outputId": "e81b13e2-b2b7-4ff1-f1f7-e833844b8266"
   },
   "outputs": [],
   "source": [
    "# Comprobar con los resultados de referencia (modelo 0)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IMS_sBOnvUc"
   },
   "source": [
    "En este caso, parece que agregar no linealidades a nuestro modelo hizo que rindiera peor que el modelo base.\n",
    "\n",
    "- Esto es algo a tener en cuenta en el aprendizaje autom√°tico, a veces lo que pensabas que deber√≠a funcionar no lo hace. Y luego lo que pensabas que podr√≠a no funcionar, s√≠ lo hace. Es parte ciencia, parte arte.\n",
    "\n",
    "A juzgar por los resultados, parece que nuestro modelo est√° **sobreajust√°ndose** a los datos de entrenamiento.\n",
    "\n",
    "- El sobreajuste significa que nuestro modelo est√° aprendiendo bien los datos de entrenamiento, pero esos patrones no se generalizan a los datos de prueba.\n",
    "\n",
    "Dos de las principales formas de solucionar el sobreajuste incluyen:\n",
    "\n",
    "1. Usar un modelo m√°s peque√±o o diferente (algunos modelos se ajustan mejor a ciertos tipos de datos que otros).\n",
    "2. Usar un conjunto de datos m√°s grande (cuantos m√°s datos, m√°s posibilidades tiene un modelo de aprender patrones generalizables).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVqzaBdkrMpi"
   },
   "source": [
    "## 6. Redes Neuronales Convolucionales (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QH4433WJp6J5"
   },
   "source": [
    "Las [Redes Neuronales Convolucionales](https://es.wikipedia.org/wiki/Red_neuronal_convolucional) (CNNs o ConvNets) son conocidas por su capacidad para encontrar patrones en datos visuales.\n",
    "\n",
    "- Y como estamos trabajando con datos visuales, veamos si el uso de un modelo CNN puede mejorar nuestro modelo base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXUYLxbLt5Tk"
   },
   "source": [
    "### Operaci√≥n de Convoluci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8PMj7Hht6Ia"
   },
   "source": [
    "Una CNN se caracteriza por una operaci√≥n de convoluci√≥n que se realiza \"t√≠picamente\" sobre una imagen bidimensional, $I\\in \\mathbb{R}^{n\\times m}$, como entrada, usando un kernel o filtro, $k\\in \\mathbb{R}^{p\\times q}$, bidimensional y que nos da como resultado una nueva imagen ser√≠a:\n",
    "\n",
    "<center>\n",
    "$I_n(i,j) = (I * k)(i, j) = \\sum_{m} \\sum_{n} I(m, n) \\cdot k(i-m, j-n)$\n",
    "</center>\n",
    "\n",
    "\n",
    "Graficamente la convoluci√≥n se ve as√≠:\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/7maczejdeej0qoz3pzkysw0y8qb70g2h.png\" alt=\"HTML5 Icon\" style=\"width: 500px; height: 200px;\">\n",
    "<center>  Illustration of the operation for one position of the kernel. <a href=\"http://colah.github.io/posts/2014-07-Understanding-Convolutions/\">ref</a></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFc4ijaJuMGK"
   },
   "source": [
    "Afortunadamente para nosotros, PyTorch y en genral cualquier *framwork* de ML ya tiene implementada:\n",
    "\n",
    "- La operaci√≥n de convoluci√≥n, adem√°s de otras como:\n",
    "  - el *padding* y\n",
    "  - el *pooling*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAposkhb2T1c"
   },
   "source": [
    "### Otras Operaciones - Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOrAcvEhucjS"
   },
   "source": [
    "\n",
    "\n",
    "*Zero-padding* agrega ceros en el borde de la imagen:\n",
    "\n",
    "<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/PAD.png?raw=1\" style=\"width:600px;height:400px;\">\n",
    "<caption><center>Zero-Padding. Imagen de 3 canales (RGB) con un padding de 2. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXBEIo-k2YZ5"
   },
   "source": [
    "### Otras Operaciones - Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQJ-VZP42Qgu"
   },
   "source": [
    "<table>\n",
    "<td>\n",
    "<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/max_pool1.png?raw=1\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/a_pool.png?raw=1\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oywc3gkr2jiN"
   },
   "source": [
    "### Construyendo un modelo de CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_0MuaWk2j8P"
   },
   "source": [
    "El modelo de CNN que vamos a usar se conoce como TinyVGG, del sitio web [CNN Explainer](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "Este modelo sigue la estructura t√≠pica de una red neuronal convolucional:\n",
    "\n",
    "`Capa de entrada -> [Capa convolucional -> capa de activaci√≥n -> capa de pooling] -> Capa de salida`\n",
    "\n",
    "Donde el contenido de `[Capa convolucional -> capa de activaci√≥n -> capa de pooling]` puede escalarse y repetirse varias veces, dependiendo de los requisitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iik0iTPc3VM7"
   },
   "source": [
    "La estructura de la CNN, en este caso la TinyVGG, es la siguiente:\n",
    "\n",
    "![modelo base](https://drive.google.com/uc?id=1kyYrfQqTjTriykEc0ONYGyuczM7mOLL4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOmbyDlG3csZ"
   },
   "source": [
    "#### Biblioteca de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjFv_zsYnoYX"
   },
   "outputs": [],
   "source": [
    "# Importando PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#  matplotlib para visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "#print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wTBYGMkQ3i7N",
    "outputId": "82ac8448-ff09-486b-940e-61fcc4fd34e6"
   },
   "outputs": [],
   "source": [
    "# Seleccionando el dispositivo (cpu/gpu)\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-yb5OgE386J"
   },
   "source": [
    "#### Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJIJLuYy30Y8",
    "outputId": "08c1020a-d274-4780-e853-87e9ecfb8a26"
   },
   "outputs": [],
   "source": [
    "# Create a convolutional neural network\n",
    "class CNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from:\n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3, # Tamnio del \"kernle\"\n",
    "                      stride=1, # default\n",
    "                      padding=1),# Agregando o no \"padding\"\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # \"paso\" del kernel\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*8*8,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Cloque su c√≥digo aqu√≠:\n",
    "#   Tamanio de la entrada (canales)\n",
    "in_tamanio =\n",
    "#   Cantidad de filtros\n",
    "num_kernels =\n",
    "#   Cantidad de clases\n",
    "num_clases =\n",
    "\n",
    "model_cnn = CNNModel(input_shape=in_tamanio,\n",
    "    hidden_units=num_kernels,\n",
    "    output_shape=num_clases).to(device)\n",
    "model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIHg7Tqn4luG"
   },
   "source": [
    "Las dos nuevas capas que hemos agregado son:\n",
    "* [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), tambi√©n conocida como capa convolucional.\n",
    "* [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), tambi√©n conocida como capa de *max Pooling*.\n",
    "\n",
    "> **Nota:**\n",
    ">\n",
    "> El 2d se refiere a datos bidimensionales. Es decir, nuestras im√°genes tienen dos dimensiones: altura y anchura.\n",
    ">\n",
    "> Para otros tipos de datos (como 1D para texto o 3D para objetos tridimensionales) tambi√©n existen `nn.Conv1d()` y `nn.Conv3d()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2c80jrs4sBy"
   },
   "source": [
    "#### Un vistazo a la capa de convoluci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsEf-7hO4sKn"
   },
   "source": [
    "\n",
    "![ejemplo de los diferentes par√°metros de una capa Conv2d](https://drive.google.com/uc?id=1MJZshpaKCGUHmyLNcRGCWrH5UyCBRopS)\n",
    "\n",
    "*Ejemplo de lo que ocurre al cambiar los hiperpar√°metros de una capa `nn.Conv2d()`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "si70BJ6E44uO"
   },
   "source": [
    "\n",
    "Esencialmente, **cada capa en una red neuronal intenta comprimir datos de un espacio de mayor dimensi√≥n a un espacio de menor dimensi√≥n**.\n",
    "\n",
    "En otras palabras, toma muchos n√∫meros (datos crudos) y aprende patrones en esos n√∫meros; patrones que son predictivos y, al mismo tiempo, *m√°s peque√±os* en tama√±o que los valores originales.\n",
    "\n",
    "Desde una perspectiva de inteligencia artificial, podr√≠as considerar que el objetivo de una red neuronal es *comprimir* la informaci√≥n.\n",
    "\n",
    "![cada capa de una red neuronal comprime los datos de entrada originales en una representaci√≥n m√°s peque√±a que, con suerte, es capaz de hacer predicciones en datos de entrada futuros](https://drive.google.com/uc?id=1j7odSUhojI5wLT4M03eSh0X4S_BL641j)\n",
    "\n",
    "\n",
    "Esto significa que, desde el punto de vista de una red neuronal, la inteligencia es compresi√≥n.\n",
    "\n",
    "Esta es la idea del uso de una capa `nn.MaxPool2d()`: tomar el valor m√°ximo de una porci√≥n de un tensor y descartar el resto.\n",
    "\n",
    "En esencia, se reduce la dimensionalidad de un tensor mientras se retiene una (esperemos) porci√≥n significativa de la informaci√≥n.\n",
    "\n",
    "Es lo mismo para una capa `nn.Conv2d()`.\n",
    "\n",
    "Excepto que, en lugar de tomar solo el valor m√°ximo, `nn.Conv2d()` realiza una operaci√≥n de convoluci√≥n en los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU9hUjYF5_jk"
   },
   "source": [
    "#### Configurando la funci√≥n de p√©rdida y el optimizador para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9PGwFaz5_7P"
   },
   "source": [
    "Ya hemos analizado lo suficiente las capas en nuestra primera CNN.\n",
    "Ahora es momento de avanzar y comenzar el entrenamiento.\n",
    "\n",
    "Vamos a configurar una funci√≥n de p√©rdida y un optimizador.\n",
    "\n",
    "Usaremos las mismas funciones que antes: `nn.CrossEntropyLoss()` como funci√≥n de p√©rdida (ya que estamos trabajando con datos de clasificaci√≥n multiclase).\n",
    "\n",
    "Y `torch.optim.SGD()` como optimizador para optimizar `model_2.parameters()` con una tasa de aprendizaje de `0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bs9OZP5h3t_Q"
   },
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_cnn.parameters(),\n",
    "                             lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3aiVHFp6PoE"
   },
   "source": [
    "#### Entrenando y probando el `model_cnn` usando nuestras funciones de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tcmMUAq6PyD"
   },
   "source": [
    "Es momento de entrenar y probar.\n",
    "\n",
    "Usaremos nuestras funciones `train_step()` y `test_step()` que creamos antes.\n",
    "\n",
    "Tambi√©n mediremos el tiempo para compararlo con nuestros otros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuG_d7MM6KU5"
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Enviando al dispositivo (GPU/CPU)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculando p√©rdida (loss)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Gradientes a cero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calcule la p√©rdida y la exactitud por √©poca e imprima lo que est√° sucediendo\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # poner el modelo en modo de evaluaci√≥n\n",
    "\n",
    "    # Activar el modo de inferencia\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Enviando al dispositivo (GPU/CPU)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculando p√©rdida (loss) y exactitud (accuracy)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1)\n",
    "            )\n",
    "\n",
    "        # Mostrando el resultado\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HahNvMt-6Y8d"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format).\n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI0wg6nc6cqB"
   },
   "outputs": [],
   "source": [
    "# Calculando excactitud (accuracy)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327,
     "referenced_widgets": [
      "6e3d05b201954b5eaea6d30284c17d07",
      "ca3c93aede904ea8a8a6b98f040ae923",
      "b37de64eea8f4e0b9c55a889f575c194",
      "da3e9f34ae8549f9aa799f2bb05a4a06",
      "fad1407cfa5c4af48fad6e8fa6bcbe7d",
      "d96d7144313541d5a156bda73ab9a18d",
      "a7c7ea16d2d341f28328fac237759840",
      "475301bc644342a1beb390220a49c51c",
      "08298ec8959e486383bd6c34bd29d0e9",
      "d452ad13b3f24208855e3a7154c915e0",
      "d82077be9a0a46b49f5bead9680289ff"
     ]
    },
    "id": "U4fWf1pQ6eq1",
    "outputId": "c498f1af-14e3-4d7a-a493-1b5542840f54"
   },
   "outputs": [],
   "source": [
    "# tqdm para barra de progreso\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader,\n",
    "        model=model_cnn,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(\n",
    "        data_loader=valid_dataloader,\n",
    "        model=model_cnn,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkIkd7yn818u"
   },
   "source": [
    "Parece que las capas convolucionales y de max pooling ayudaron a mejorar el rendimiento un poco.\n",
    "\n",
    "Ahora evaluemos los resultados de `model_cnn` con nuestra funci√≥n `eval_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHi1OB6h7IDH"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluates a given model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Datos al dispositivo\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # loss y acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDNhCOWa9DeW",
    "outputId": "8a8dfdba-38b9-4d22-e684-cab33a815998"
   },
   "outputs": [],
   "source": [
    "# Obteniendo resultados\n",
    "model_cnn_results = eval_model(\n",
    "    model=model_cnn,\n",
    "    #data_loader=test_dataloader,\n",
    "    data_loader=valid_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_cnn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz6wOK-F9QUR"
   },
   "source": [
    "#### CNN - Predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orowyZwj9OFg"
   },
   "source": [
    "Veamos ahora como se son algunas de las predicciones\n",
    "\n",
    "\n",
    "Para hacerlo, vamos a crear una funci√≥n llamada `make_predictions()` donde podamos pasar el modelo y algunos datos para que haga predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j80f6T1T9JmF"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Preparando la muestra\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Obteniendo predicci√≥n (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
    "\n",
    "            # Obtenga pred_prob de la GPU para realizar c√°lculos adicionales\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    # Apila los pred_probs para convertir la lista en un tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaDmVN6t9YVr"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_dataset), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpGAOdVQ977h"
   },
   "outputs": [],
   "source": [
    "# Haciendo predicciones con los datos de prueba (test samples)\n",
    "pred_probs= make_predictions(model=model_cnn,\n",
    "                             data=test_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w-yPfZCL7E2"
   },
   "source": [
    "Visualizando una de las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "MSWJtc9SKIAF",
    "outputId": "87c6d590-b5d5-4120-f71a-a77cd2914a86"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "iTest=4\n",
    "fig, (ax1, ax2) = plt.subplots( ncols=2)\n",
    "y = pred_probs[iTest].detach().numpy()\n",
    "y = (y - min(y))/(max(y)-min(y))\n",
    "ax2.axis('off')\n",
    "ax2.imshow(test_samples[iTest].squeeze(), cmap=\"gray\")\n",
    "ax1.set_title('Probabilidad')\n",
    "ax1.set_yticks(np.arange(43))\n",
    "ax1.barh(np.arange(43), y)\n",
    "ax1.set_yticklabels(class_names,fontsize=6)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqy5I9EFA8qN"
   },
   "source": [
    "Ahora podemos convertir las probabilidades de predicci√≥n en etiquetas de predicci√≥n tomando el `torch.argmax()` de la salida de la funci√≥n de activaci√≥n `torch.softmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDdn2GrfA4km",
    "outputId": "248237ca-a532-44c2-d09d-0c12f6824355"
   },
   "outputs": [],
   "source": [
    "# Convierta las probabilidades de predicci√≥n en etiquetas de predicci√≥n tomando argmax()\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "BCVf6crUBABt",
    "outputId": "3a52e435-7913-4374-ab6e-451c5a60e9c6"
   },
   "outputs": [],
   "source": [
    "# Graficando las predicciones\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "  # Create a subplot\n",
    "  plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "  # Plot the target image\n",
    "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "  pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "  truth_label = class_names[test_labels[i]]\n",
    "\n",
    "  # Create the title text of the plot\n",
    "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "\n",
    "  # Check for equality and change title colour accordingly\n",
    "  #if pred_label == truth_label:\n",
    "  if pred_classes[i] == test_labels[i]:\n",
    "      plt.title(title_text, fontsize=6, c=\"g\") # green text if correct\n",
    "  else:\n",
    "      plt.title(title_text, fontsize=6, c=\"r\") # red text if wrong\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wPSYYrkzOII"
   },
   "source": [
    "### Probando la Generalizaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdAWwv6tBDT3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-NGbsJt4HWm",
    "outputId": "2d6843bd-ab54-4bd4-aa5a-e4e26cc7919b"
   },
   "outputs": [],
   "source": [
    "# --- CONFIGURACI√ìN ---\n",
    "# ‚ö†Ô∏è IMPORTANTE: REEMPLAZA ESTE ID con el ID del archivo o carpeta p√∫blica de Google Drive.\n",
    "# El ID es la parte de la URL que est√° despu√©s de 'id='\n",
    "# Ejemplo: si la URL es https://drive.google.com/file/d/1Bhmv_m3.../view, el ID es 1Bhmv_m3...\n",
    "ID_PUBLICO_DRIVE = '12IKVEKXU4VYozR-PdGPofU7jyAa00MJy' # Ejemplo: 1u-R6L6vY7...\n",
    "NOMBRE_DESTINO = 'some_imgs.zip' # El nombre que tendr√° el archivo al descargarse\n",
    "\n",
    "\n",
    "# Paso 2: Ejecutar la descarga\n",
    "try:\n",
    "    print(f\"Intentando descargar el ID: {ID_PUBLICO_DRIVE}\")\n",
    "    gdown.download(id=ID_PUBLICO_DRIVE, output=NOMBRE_DESTINO, quiet=False)\n",
    "\n",
    "    if os.path.exists(NOMBRE_DESTINO):\n",
    "        print(f\"\\n‚úÖ ¬°Descarga exitosa! Archivo guardado como: {NOMBRE_DESTINO}\")\n",
    "        # Si es un ZIP, puedes descomprimirlo inmediatamente\n",
    "        if NOMBRE_DESTINO.endswith('.zip'):\n",
    "            !unzip {NOMBRE_DESTINO} -d /content/some_imgs\n",
    "            print(\"Archivo descomprimido.\")\n",
    "            !rm /content/{NOMBRE_DESTINO}\n",
    "    else:\n",
    "         print(\"\\n‚ö†Ô∏è Advertencia: No se pudo verificar la descarga. Revisa el ID y los permisos.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error durante la descarga: {e}\")\n",
    "\n",
    "# No descomentar Comando para eliminar la carpete\n",
    "#!rm -rf /content/some_imgs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dXjuCBHROIP"
   },
   "source": [
    "Leyendo la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "4EHGgDCh4gSH",
    "outputId": "e270a1f2-f53a-45fa-eef9-2b76e04f4a51"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Obtener el nombre del archivo\n",
    "\n",
    "#filename = \"some_imgs/no_entry.png\"\n",
    "#filename = \"some_imgs/turn_right_ahead.png\"\n",
    "#filename = \"some_imgs/turn_left_ahead.png\"\n",
    "filename = \"some_imgs/ahead_only.png\"\n",
    "\n",
    "print(f\"‚úÖ Archivo cargado: {filename}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Leer la imagen con OpenCV\n",
    "img_bgr = cv2.imread(filename)\n",
    "\n",
    "# Verificar que la imagen se haya cargado\n",
    "if img_bgr is None:\n",
    "    raise ValueError(\"‚ùå No se pudo leer la imagen. Aseg√∫rate de que el archivo es v√°lido (JPG, PNG, etc.)\")\n",
    "\n",
    "# Convertir de BGR a RGB (para mostrar correctamente con Matplotlib)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.figure()\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"Imagen cargada con OpenCV\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Ver dimensiones\n",
    "print(f\"Dimensiones de la imagen: {img_rgb.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2W1q1mxWRqW6"
   },
   "source": [
    "Escalando la imagne (32x32) y convirtiendola en una imagen en escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gNZGA_Z5OVk"
   },
   "outputs": [],
   "source": [
    "# Redimensionar la imagen a 32x32 p√≠xeles\n",
    "img_resized = cv2.resize(img_rgb, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# --- Convertir a escala de grises ---\n",
    "# Usamos la expresi√≥n luminancia: Y = 0.299R + 0.587G + 0.114B\n",
    "def rgb2gray(img):\n",
    "    return (\n",
    "        0.299 * img[:,:,0] +\n",
    "        0.587 * img[:,:,1] +\n",
    "        0.114 * img[:,:,2]\n",
    "    )\n",
    "\n",
    "img_gray = rgb2gray(img_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "OdX8J3b2Sh2h",
    "outputId": "440dba91-ab3c-42ba-bdb7-a24194837750"
   },
   "outputs": [],
   "source": [
    "# Mostrar la imagen\n",
    "plt.figure()\n",
    "plt.imshow(img_gray, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Imagen 32x32 en gris\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Ver dimensiones\n",
    "print(f\"Dimensiones de la imagen: {img_gray.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvcqgZT_ThPf"
   },
   "source": [
    "Haciendo la predicci√≥n de la clase con el modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0lRpkWrSn8W",
    "outputId": "e3a46d2d-1986-4beb-de69-ebd9c96acf26"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convertir a tipo float y normalizar valores entre 0 y 1\n",
    "img_norm = img_gray.astype(np.float32) / 255.0\n",
    "\n",
    "# Convertir el array numpy en tensor de PyTorch\n",
    "img_tensor = torch.tensor(img_norm)\n",
    "\n",
    "# A√±adir las dimensiones requeridas:\n",
    "#     (1 canal, alto, ancho) ‚Üí (1, 32, 32)0\n",
    "#     y luego a√±adir el batch ‚Üí (1, 1, 32, 32)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "# Mostrar informaci√≥n del tensor\n",
    "print(f\"‚úÖ Tensor creado con forma: {img_tensor.shape}\")\n",
    "print(f\"Tipo de dato: {img_tensor.dtype}\")\n",
    "print(f\"Valores m√≠nimos y m√°ximos: {img_tensor.min():.3f}, {img_tensor.max():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9w5B9oKVMA8"
   },
   "source": [
    "Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3j7GyRJTbl8",
    "outputId": "74a93344-79f2-4e34-8e6c-8111445cb0b8"
   },
   "outputs": [],
   "source": [
    "# Inferencia\n",
    "pred_probs= make_predictions(model=model_cnn,\n",
    "                             data=[img_tensor])\n",
    "print(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "KKoz4-tJVSme",
    "outputId": "f334202e-f2e7-4e9b-9549-bd51e5a6df19"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots( ncols=2)\n",
    "y = pred_probs[0].detach().numpy()\n",
    "y = (y - min(y))/(max(y)-min(y))\n",
    "ax2.axis('off')\n",
    "ax2.imshow(img_gray, cmap=\"gray\")\n",
    "ax1.set_title('Probabilidad')\n",
    "ax1.set_yticks(np.arange(43))\n",
    "ax1.barh(np.arange(43), y)\n",
    "ax1.set_yticklabels(class_names,fontsize=6)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3B3mySdAVyDR",
    "outputId": "eb630f57-7928-4dea-8fe5-f542e2e5828e"
   },
   "outputs": [],
   "source": [
    "# Convierta las probabilidades de predicci√≥n en etiquetas de predicci√≥n tomando argmax()\n",
    "pred_class = pred_probs.argmax(dim=1)\n",
    "print(f\"Clase inferida: \\n\\t{class_names[pred_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-91N4x8Rh5Q"
   },
   "source": [
    "### Guardando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVqA2ausGRnH",
    "outputId": "735178e8-28b1-4b50-d87d-dbf5c76243a6"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"CNN_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_cnn.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M73xr_3Ld5d2"
   },
   "source": [
    "## Pr√°ctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "id": "906TAP_QhwuJ",
    "outputId": "adda3117-4fcd-4a20-8392-337a1eb5eeaf"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üì∏ Capturar imagen desde la c√°mara con reflejo vertical (Colab)\n",
    "# ============================================================\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.9):\n",
    "    js = Javascript('''\n",
    "      async function takePhoto(quality) {\n",
    "        const div = document.createElement('div');\n",
    "        const capture = document.createElement('button');\n",
    "        capture.textContent = 'üì∏ Capturar';\n",
    "        div.appendChild(capture);\n",
    "        document.body.appendChild(div);\n",
    "\n",
    "        // Activar c√°mara\n",
    "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "        const video = document.createElement('video');\n",
    "        video.srcObject = stream;\n",
    "        await video.play();\n",
    "\n",
    "        // Crear canvas\n",
    "        const canvas = document.createElement('canvas');\n",
    "        document.body.appendChild(video);\n",
    "        document.body.appendChild(canvas);\n",
    "\n",
    "        // Esperar click en el bot√≥n \"capturar\"\n",
    "        await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "        // Ajustar tama√±o del canvas\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "\n",
    "        // Obtener contexto del canvas\n",
    "        const ctx = canvas.getContext('2d');\n",
    "\n",
    "        // Reflejar el video en el eje vertical (efecto espejo)\n",
    "        ctx.translate(canvas.width, 0);\n",
    "        ctx.scale(-1, 1);\n",
    "\n",
    "        // Dibujar el fotograma reflejado\n",
    "        ctx.drawImage(video, 0, 0);\n",
    "\n",
    "        // Detener la c√°mara\n",
    "        stream.getTracks().forEach(track => track.stop());\n",
    "        div.remove();\n",
    "        video.remove();\n",
    "\n",
    "        // Devolver la imagen como base64\n",
    "        return canvas.toDataURL('image/jpeg', quality);\n",
    "      }\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "    return filename\n",
    "\n",
    "try:\n",
    "    filename = take_photo()\n",
    "    print(f\"‚úÖ Imagen capturada y guardada como {filename}\")\n",
    "\n",
    "    # Leer con OpenCV y mostrar\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Reflejar sobre el eje vertical\n",
    "    flipped = cv2.flip(img_rgb, 1)\n",
    "\n",
    "    plt.imshow(flipped)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Imagen capturada\")\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error al acceder a la c√°mara:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "t8UMgq-mb0qe",
    "outputId": "dadabcfc-5296-4fda-e7af-3fc516749ffc"
   },
   "outputs": [],
   "source": [
    "# Leer la imagen con OpenCV\n",
    "filename = 'photo.jpg'\n",
    "\n",
    "img_bgr = cv2.imread(filename)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Escalar a 32x32\n",
    "img_resized = cv2.resize(img_rgb, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Convertir a escala de grises\n",
    "img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Mostrar resultados\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_resized)\n",
    "plt.title(\"RGB\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_gray, cmap=\"gray\")\n",
    "plt.title(\"Gris\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Imagen de color (RGB): {img_resized.shape}\")\n",
    "print(f\"Imagen en Gris: {img_gray.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HK2gwHCAdBJB",
    "outputId": "7f7a6745-0ee9-46d8-d27c-da8a899e16c4"
   },
   "outputs": [],
   "source": [
    "# Convertir a tipo float y normalizar valores entre 0 y 1\n",
    "img_norm = img_gray.astype(np.float32) / 255.0\n",
    "\n",
    "# Convertir el array numpy en tensor de PyTorch\n",
    "img_tensor = torch.tensor(img_norm)\n",
    "\n",
    "# A√±adir las dimensiones requeridas:\n",
    "#     (1 canal, alto, ancho) ‚Üí (1, 32, 32)0\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "# Mostrar informaci√≥n del tensor\n",
    "print(f\"‚úÖ Tensor creado con forma: {img_tensor.shape}\")\n",
    "print(f\"Tipo de dato: {img_tensor.dtype}\")\n",
    "print(f\"Valores m√≠nimos y m√°ximos: {img_tensor.min():.3f}, {img_tensor.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HLyHSSZd2jq",
    "outputId": "c844e62f-3fa7-4b73-ce22-4dd124f4c804"
   },
   "outputs": [],
   "source": [
    "# Realizar predicciones sobre muestras de prueba con el modelo CNN\n",
    "pred_probs= make_predictions(model=model_cnn,\n",
    "                             data=[img_tensor])\n",
    "\n",
    "# Convierta las probabilidades de predicci√≥n en etiquetas de predicci√≥n tomando argmax()\n",
    "pred_class = pred_probs.argmax(dim=1)\n",
    "print(f\"Clase inferida: \\n\\t{class_names[pred_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIuTbFGyCSg0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
